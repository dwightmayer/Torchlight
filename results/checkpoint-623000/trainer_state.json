{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 99.68,
  "eval_steps": 500,
  "global_step": 623000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16,
      "grad_norm": 2.2418787479400635,
      "learning_rate": 4.992e-05,
      "loss": 6.7055,
      "step": 1000
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0488848686218262,
      "learning_rate": 4.9840000000000004e-05,
      "loss": 3.9209,
      "step": 2000
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0931888818740845,
      "learning_rate": 4.976e-05,
      "loss": 3.3433,
      "step": 3000
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.273848533630371,
      "learning_rate": 4.9680000000000005e-05,
      "loss": 3.1501,
      "step": 4000
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0128235816955566,
      "learning_rate": 4.96e-05,
      "loss": 3.0525,
      "step": 5000
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0469470024108887,
      "learning_rate": 4.952008e-05,
      "loss": 2.9708,
      "step": 6000
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7900944948196411,
      "learning_rate": 4.944008e-05,
      "loss": 2.8714,
      "step": 7000
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.0412187576293945,
      "learning_rate": 4.936016e-05,
      "loss": 2.7872,
      "step": 8000
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.125714063644409,
      "learning_rate": 4.928016e-05,
      "loss": 2.7382,
      "step": 9000
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.1534245014190674,
      "learning_rate": 4.920016e-05,
      "loss": 2.6844,
      "step": 10000
    },
    {
      "epoch": 1.76,
      "grad_norm": 1.241438388824463,
      "learning_rate": 4.912024e-05,
      "loss": 2.6232,
      "step": 11000
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.5716214179992676,
      "learning_rate": 4.904024e-05,
      "loss": 2.5984,
      "step": 12000
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.706678032875061,
      "learning_rate": 4.896024e-05,
      "loss": 2.5385,
      "step": 13000
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.3662282228469849,
      "learning_rate": 4.888024e-05,
      "loss": 2.4961,
      "step": 14000
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.362504482269287,
      "learning_rate": 4.880032e-05,
      "loss": 2.4216,
      "step": 15000
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.7251365184783936,
      "learning_rate": 4.87204e-05,
      "loss": 2.3889,
      "step": 16000
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.5846168994903564,
      "learning_rate": 4.86404e-05,
      "loss": 2.3543,
      "step": 17000
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.5966707468032837,
      "learning_rate": 4.8560400000000004e-05,
      "loss": 2.3448,
      "step": 18000
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.3826017379760742,
      "learning_rate": 4.8480400000000004e-05,
      "loss": 2.2799,
      "step": 19000
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.4745063781738281,
      "learning_rate": 4.8400480000000004e-05,
      "loss": 2.2111,
      "step": 20000
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.8397321701049805,
      "learning_rate": 4.8320480000000005e-05,
      "loss": 2.1986,
      "step": 21000
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.9187867641448975,
      "learning_rate": 4.8240480000000005e-05,
      "loss": 2.1653,
      "step": 22000
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.4221183061599731,
      "learning_rate": 4.8160560000000005e-05,
      "loss": 2.1121,
      "step": 23000
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.6621495485305786,
      "learning_rate": 4.808056e-05,
      "loss": 2.0713,
      "step": 24000
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.600146770477295,
      "learning_rate": 4.8000640000000005e-05,
      "loss": 2.0648,
      "step": 25000
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.8875600099563599,
      "learning_rate": 4.792064e-05,
      "loss": 2.0015,
      "step": 26000
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.8752270936965942,
      "learning_rate": 4.784064e-05,
      "loss": 1.9728,
      "step": 27000
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.130988836288452,
      "learning_rate": 4.7760720000000006e-05,
      "loss": 1.9373,
      "step": 28000
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.58014976978302,
      "learning_rate": 4.768072e-05,
      "loss": 1.8916,
      "step": 29000
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.670214295387268,
      "learning_rate": 4.76008e-05,
      "loss": 1.8553,
      "step": 30000
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.7921582460403442,
      "learning_rate": 4.752080000000001e-05,
      "loss": 1.8505,
      "step": 31000
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.5141466856002808,
      "learning_rate": 4.744088000000001e-05,
      "loss": 1.8073,
      "step": 32000
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.6258082389831543,
      "learning_rate": 4.736088e-05,
      "loss": 1.7381,
      "step": 33000
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.7146600484848022,
      "learning_rate": 4.728088e-05,
      "loss": 1.7181,
      "step": 34000
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.3209940195083618,
      "learning_rate": 4.720096e-05,
      "loss": 1.7012,
      "step": 35000
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.6463721990585327,
      "learning_rate": 4.712096e-05,
      "loss": 1.6816,
      "step": 36000
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.937723994255066,
      "learning_rate": 4.704104e-05,
      "loss": 1.6412,
      "step": 37000
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.8506805896759033,
      "learning_rate": 4.696104e-05,
      "loss": 1.6099,
      "step": 38000
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.9230496883392334,
      "learning_rate": 4.688104e-05,
      "loss": 1.562,
      "step": 39000
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.4331958293914795,
      "learning_rate": 4.680112e-05,
      "loss": 1.5448,
      "step": 40000
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.5244874954223633,
      "learning_rate": 4.6721120000000004e-05,
      "loss": 1.5153,
      "step": 41000
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.5259121656417847,
      "learning_rate": 4.66412e-05,
      "loss": 1.4719,
      "step": 42000
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.7272801399230957,
      "learning_rate": 4.6561200000000004e-05,
      "loss": 1.4643,
      "step": 43000
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.66228449344635,
      "learning_rate": 4.6481200000000005e-05,
      "loss": 1.442,
      "step": 44000
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.6365711688995361,
      "learning_rate": 4.6401280000000004e-05,
      "loss": 1.3749,
      "step": 45000
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.5601704120635986,
      "learning_rate": 4.632128e-05,
      "loss": 1.3526,
      "step": 46000
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.6854941844940186,
      "learning_rate": 4.624136e-05,
      "loss": 1.3378,
      "step": 47000
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.1862616539001465,
      "learning_rate": 4.6161360000000006e-05,
      "loss": 1.3229,
      "step": 48000
    },
    {
      "epoch": 7.84,
      "grad_norm": 2.177284002304077,
      "learning_rate": 4.6081440000000005e-05,
      "loss": 1.302,
      "step": 49000
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.7850298881530762,
      "learning_rate": 4.600144e-05,
      "loss": 1.2725,
      "step": 50000
    },
    {
      "epoch": 8.16,
      "grad_norm": 3.0071768760681152,
      "learning_rate": 4.5921600000000004e-05,
      "loss": 1.2088,
      "step": 51000
    },
    {
      "epoch": 8.32,
      "grad_norm": 2.217179775238037,
      "learning_rate": 4.58416e-05,
      "loss": 1.1968,
      "step": 52000
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.1660425662994385,
      "learning_rate": 4.5761600000000006e-05,
      "loss": 1.1719,
      "step": 53000
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.6174933910369873,
      "learning_rate": 4.5681680000000005e-05,
      "loss": 1.16,
      "step": 54000
    },
    {
      "epoch": 8.8,
      "grad_norm": 2.0450565814971924,
      "learning_rate": 4.560168e-05,
      "loss": 1.1584,
      "step": 55000
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.2697641849517822,
      "learning_rate": 4.552168e-05,
      "loss": 1.1263,
      "step": 56000
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.847775936126709,
      "learning_rate": 4.544168e-05,
      "loss": 1.0845,
      "step": 57000
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.8076499700546265,
      "learning_rate": 4.536176e-05,
      "loss": 1.0375,
      "step": 58000
    },
    {
      "epoch": 9.44,
      "grad_norm": 2.2431774139404297,
      "learning_rate": 4.528176e-05,
      "loss": 1.0338,
      "step": 59000
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.6431338787078857,
      "learning_rate": 4.520184e-05,
      "loss": 1.0194,
      "step": 60000
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.6158770322799683,
      "learning_rate": 4.512184e-05,
      "loss": 0.9818,
      "step": 61000
    },
    {
      "epoch": 9.92,
      "grad_norm": 2.1504900455474854,
      "learning_rate": 4.504184e-05,
      "loss": 0.9835,
      "step": 62000
    },
    {
      "epoch": 10.08,
      "grad_norm": 1.5775846242904663,
      "learning_rate": 4.496192e-05,
      "loss": 0.9632,
      "step": 63000
    },
    {
      "epoch": 10.24,
      "grad_norm": 2.2853260040283203,
      "learning_rate": 4.488192e-05,
      "loss": 0.9074,
      "step": 64000
    },
    {
      "epoch": 10.4,
      "grad_norm": 3.488847017288208,
      "learning_rate": 4.4802e-05,
      "loss": 0.9039,
      "step": 65000
    },
    {
      "epoch": 10.56,
      "grad_norm": 1.6726971864700317,
      "learning_rate": 4.4722e-05,
      "loss": 0.8762,
      "step": 66000
    },
    {
      "epoch": 10.72,
      "grad_norm": 1.6510857343673706,
      "learning_rate": 4.464208e-05,
      "loss": 0.8818,
      "step": 67000
    },
    {
      "epoch": 10.88,
      "grad_norm": 1.6616917848587036,
      "learning_rate": 4.4562080000000003e-05,
      "loss": 0.8605,
      "step": 68000
    },
    {
      "epoch": 11.04,
      "grad_norm": 2.6510419845581055,
      "learning_rate": 4.448224e-05,
      "loss": 0.8313,
      "step": 69000
    },
    {
      "epoch": 11.2,
      "grad_norm": 3.433029890060425,
      "learning_rate": 4.440224e-05,
      "loss": 0.8045,
      "step": 70000
    },
    {
      "epoch": 11.36,
      "grad_norm": 2.2987003326416016,
      "learning_rate": 4.4322240000000003e-05,
      "loss": 0.7956,
      "step": 71000
    },
    {
      "epoch": 11.52,
      "grad_norm": 1.6990580558776855,
      "learning_rate": 4.424232e-05,
      "loss": 0.7752,
      "step": 72000
    },
    {
      "epoch": 11.68,
      "grad_norm": 1.8404659032821655,
      "learning_rate": 4.4162320000000004e-05,
      "loss": 0.7603,
      "step": 73000
    },
    {
      "epoch": 11.84,
      "grad_norm": 2.5817878246307373,
      "learning_rate": 4.4082320000000005e-05,
      "loss": 0.7553,
      "step": 74000
    },
    {
      "epoch": 12.0,
      "grad_norm": 2.02937912940979,
      "learning_rate": 4.4002320000000005e-05,
      "loss": 0.7368,
      "step": 75000
    },
    {
      "epoch": 12.16,
      "grad_norm": 2.047929048538208,
      "learning_rate": 4.3922400000000005e-05,
      "loss": 0.6949,
      "step": 76000
    },
    {
      "epoch": 12.32,
      "grad_norm": 1.5670057535171509,
      "learning_rate": 4.38424e-05,
      "loss": 0.6928,
      "step": 77000
    },
    {
      "epoch": 12.48,
      "grad_norm": 2.496217727661133,
      "learning_rate": 4.3762400000000006e-05,
      "loss": 0.6779,
      "step": 78000
    },
    {
      "epoch": 12.64,
      "grad_norm": 1.5584986209869385,
      "learning_rate": 4.3682480000000006e-05,
      "loss": 0.6639,
      "step": 79000
    },
    {
      "epoch": 12.8,
      "grad_norm": 1.7259035110473633,
      "learning_rate": 4.360248e-05,
      "loss": 0.6524,
      "step": 80000
    },
    {
      "epoch": 12.96,
      "grad_norm": 2.0244250297546387,
      "learning_rate": 4.352256e-05,
      "loss": 0.6545,
      "step": 81000
    },
    {
      "epoch": 13.12,
      "grad_norm": 1.791203498840332,
      "learning_rate": 4.344256000000001e-05,
      "loss": 0.6182,
      "step": 82000
    },
    {
      "epoch": 13.28,
      "grad_norm": 1.2361016273498535,
      "learning_rate": 4.336256e-05,
      "loss": 0.604,
      "step": 83000
    },
    {
      "epoch": 13.44,
      "grad_norm": 1.9455983638763428,
      "learning_rate": 4.328264e-05,
      "loss": 0.5904,
      "step": 84000
    },
    {
      "epoch": 13.6,
      "grad_norm": 1.3668718338012695,
      "learning_rate": 4.320264e-05,
      "loss": 0.59,
      "step": 85000
    },
    {
      "epoch": 13.76,
      "grad_norm": 2.3098866939544678,
      "learning_rate": 4.312264e-05,
      "loss": 0.5748,
      "step": 86000
    },
    {
      "epoch": 13.92,
      "grad_norm": 0.9731112122535706,
      "learning_rate": 4.304264e-05,
      "loss": 0.5741,
      "step": 87000
    },
    {
      "epoch": 14.08,
      "grad_norm": 1.9107145071029663,
      "learning_rate": 4.2962640000000004e-05,
      "loss": 0.5548,
      "step": 88000
    },
    {
      "epoch": 14.24,
      "grad_norm": 2.2801730632781982,
      "learning_rate": 4.28828e-05,
      "loss": 0.5232,
      "step": 89000
    },
    {
      "epoch": 14.4,
      "grad_norm": 1.5451761484146118,
      "learning_rate": 4.28028e-05,
      "loss": 0.5231,
      "step": 90000
    },
    {
      "epoch": 14.56,
      "grad_norm": 1.257834553718567,
      "learning_rate": 4.272288e-05,
      "loss": 0.515,
      "step": 91000
    },
    {
      "epoch": 14.72,
      "grad_norm": 2.198770523071289,
      "learning_rate": 4.264288e-05,
      "loss": 0.5036,
      "step": 92000
    },
    {
      "epoch": 14.88,
      "grad_norm": 1.2537355422973633,
      "learning_rate": 4.256288e-05,
      "loss": 0.5007,
      "step": 93000
    },
    {
      "epoch": 15.04,
      "grad_norm": 0.4199466407299042,
      "learning_rate": 4.2482880000000005e-05,
      "loss": 0.4951,
      "step": 94000
    },
    {
      "epoch": 15.2,
      "grad_norm": 2.1720755100250244,
      "learning_rate": 4.2402960000000004e-05,
      "loss": 0.4572,
      "step": 95000
    },
    {
      "epoch": 15.36,
      "grad_norm": 1.32466721534729,
      "learning_rate": 4.232296e-05,
      "loss": 0.4557,
      "step": 96000
    },
    {
      "epoch": 15.52,
      "grad_norm": 1.887964129447937,
      "learning_rate": 4.2242960000000006e-05,
      "loss": 0.4471,
      "step": 97000
    },
    {
      "epoch": 15.68,
      "grad_norm": 1.8738625049591064,
      "learning_rate": 4.216296e-05,
      "loss": 0.4521,
      "step": 98000
    },
    {
      "epoch": 15.84,
      "grad_norm": 1.7428761720657349,
      "learning_rate": 4.2083120000000005e-05,
      "loss": 0.442,
      "step": 99000
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.171754837036133,
      "learning_rate": 4.200312e-05,
      "loss": 0.4457,
      "step": 100000
    },
    {
      "epoch": 16.16,
      "grad_norm": 3.245375394821167,
      "learning_rate": 4.192312000000001e-05,
      "loss": 0.4084,
      "step": 101000
    },
    {
      "epoch": 16.32,
      "grad_norm": 2.168571710586548,
      "learning_rate": 4.184312e-05,
      "loss": 0.4018,
      "step": 102000
    },
    {
      "epoch": 16.48,
      "grad_norm": 2.6739420890808105,
      "learning_rate": 4.17632e-05,
      "loss": 0.3992,
      "step": 103000
    },
    {
      "epoch": 16.64,
      "grad_norm": 2.0916073322296143,
      "learning_rate": 4.16832e-05,
      "loss": 0.3917,
      "step": 104000
    },
    {
      "epoch": 16.8,
      "grad_norm": 1.6001425981521606,
      "learning_rate": 4.160328e-05,
      "loss": 0.3906,
      "step": 105000
    },
    {
      "epoch": 16.96,
      "grad_norm": 1.3327268362045288,
      "learning_rate": 4.152328e-05,
      "loss": 0.3961,
      "step": 106000
    },
    {
      "epoch": 17.12,
      "grad_norm": 2.2295639514923096,
      "learning_rate": 4.144328e-05,
      "loss": 0.3706,
      "step": 107000
    },
    {
      "epoch": 17.28,
      "grad_norm": 1.7808642387390137,
      "learning_rate": 4.136328e-05,
      "loss": 0.3529,
      "step": 108000
    },
    {
      "epoch": 17.44,
      "grad_norm": 1.2271578311920166,
      "learning_rate": 4.128336e-05,
      "loss": 0.3566,
      "step": 109000
    },
    {
      "epoch": 17.6,
      "grad_norm": 2.3999173641204834,
      "learning_rate": 4.120344e-05,
      "loss": 0.3457,
      "step": 110000
    },
    {
      "epoch": 17.76,
      "grad_norm": 3.5015571117401123,
      "learning_rate": 4.112344e-05,
      "loss": 0.3475,
      "step": 111000
    },
    {
      "epoch": 17.92,
      "grad_norm": 2.0094492435455322,
      "learning_rate": 4.104344e-05,
      "loss": 0.3622,
      "step": 112000
    },
    {
      "epoch": 18.08,
      "grad_norm": 0.9218692183494568,
      "learning_rate": 4.0963519999999996e-05,
      "loss": 0.3248,
      "step": 113000
    },
    {
      "epoch": 18.24,
      "grad_norm": 1.4119449853897095,
      "learning_rate": 4.0883520000000004e-05,
      "loss": 0.3178,
      "step": 114000
    },
    {
      "epoch": 18.4,
      "grad_norm": 1.740300178527832,
      "learning_rate": 4.080352e-05,
      "loss": 0.3153,
      "step": 115000
    },
    {
      "epoch": 18.56,
      "grad_norm": 0.9607744812965393,
      "learning_rate": 4.07236e-05,
      "loss": 0.3118,
      "step": 116000
    },
    {
      "epoch": 18.72,
      "grad_norm": 2.8522088527679443,
      "learning_rate": 4.0643600000000005e-05,
      "loss": 0.3072,
      "step": 117000
    },
    {
      "epoch": 18.88,
      "grad_norm": 2.0602285861968994,
      "learning_rate": 4.05636e-05,
      "loss": 0.317,
      "step": 118000
    },
    {
      "epoch": 19.04,
      "grad_norm": 0.8457915186882019,
      "learning_rate": 4.048368e-05,
      "loss": 0.3036,
      "step": 119000
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.7250202298164368,
      "learning_rate": 4.040368e-05,
      "loss": 0.281,
      "step": 120000
    },
    {
      "epoch": 19.36,
      "grad_norm": 1.9098706245422363,
      "learning_rate": 4.032368e-05,
      "loss": 0.2842,
      "step": 121000
    },
    {
      "epoch": 19.52,
      "grad_norm": 8.68026351928711,
      "learning_rate": 4.024368e-05,
      "loss": 0.2739,
      "step": 122000
    },
    {
      "epoch": 19.68,
      "grad_norm": 0.7011450529098511,
      "learning_rate": 4.016376e-05,
      "loss": 0.2813,
      "step": 123000
    },
    {
      "epoch": 19.84,
      "grad_norm": 0.6743018627166748,
      "learning_rate": 4.008376e-05,
      "loss": 0.2771,
      "step": 124000
    },
    {
      "epoch": 20.0,
      "grad_norm": 2.8001537322998047,
      "learning_rate": 4.000376e-05,
      "loss": 0.2827,
      "step": 125000
    },
    {
      "epoch": 20.16,
      "grad_norm": 3.756181001663208,
      "learning_rate": 3.992384e-05,
      "loss": 0.2554,
      "step": 126000
    },
    {
      "epoch": 20.32,
      "grad_norm": 13.849563598632812,
      "learning_rate": 3.984384e-05,
      "loss": 0.2525,
      "step": 127000
    },
    {
      "epoch": 20.48,
      "grad_norm": 1.2230548858642578,
      "learning_rate": 3.976384e-05,
      "loss": 0.2516,
      "step": 128000
    },
    {
      "epoch": 20.64,
      "grad_norm": 1.2391538619995117,
      "learning_rate": 3.968392e-05,
      "loss": 0.2499,
      "step": 129000
    },
    {
      "epoch": 20.8,
      "grad_norm": 2.0781843662261963,
      "learning_rate": 3.960392e-05,
      "loss": 0.2501,
      "step": 130000
    },
    {
      "epoch": 20.96,
      "grad_norm": 1.0026700496673584,
      "learning_rate": 3.9523920000000004e-05,
      "loss": 0.2491,
      "step": 131000
    },
    {
      "epoch": 21.12,
      "grad_norm": 1.7967218160629272,
      "learning_rate": 3.944392e-05,
      "loss": 0.2331,
      "step": 132000
    },
    {
      "epoch": 21.28,
      "grad_norm": 1.0036852359771729,
      "learning_rate": 3.9364e-05,
      "loss": 0.2289,
      "step": 133000
    },
    {
      "epoch": 21.44,
      "grad_norm": 0.5341304540634155,
      "learning_rate": 3.9284000000000005e-05,
      "loss": 0.2248,
      "step": 134000
    },
    {
      "epoch": 21.6,
      "grad_norm": 2.0503792762756348,
      "learning_rate": 3.9204080000000005e-05,
      "loss": 0.2258,
      "step": 135000
    },
    {
      "epoch": 21.76,
      "grad_norm": 1.4996140003204346,
      "learning_rate": 3.912408e-05,
      "loss": 0.2265,
      "step": 136000
    },
    {
      "epoch": 21.92,
      "grad_norm": 1.5411322116851807,
      "learning_rate": 3.904408e-05,
      "loss": 0.2297,
      "step": 137000
    },
    {
      "epoch": 22.08,
      "grad_norm": 1.4635708332061768,
      "learning_rate": 3.896408e-05,
      "loss": 0.2117,
      "step": 138000
    },
    {
      "epoch": 22.24,
      "grad_norm": 1.7360639572143555,
      "learning_rate": 3.888416e-05,
      "loss": 0.2077,
      "step": 139000
    },
    {
      "epoch": 22.4,
      "grad_norm": 0.7519171237945557,
      "learning_rate": 3.880424e-05,
      "loss": 0.202,
      "step": 140000
    },
    {
      "epoch": 22.56,
      "grad_norm": 3.1473302841186523,
      "learning_rate": 3.872424e-05,
      "loss": 0.2033,
      "step": 141000
    },
    {
      "epoch": 22.72,
      "grad_norm": 1.3907628059387207,
      "learning_rate": 3.864424e-05,
      "loss": 0.2028,
      "step": 142000
    },
    {
      "epoch": 22.88,
      "grad_norm": 1.8181345462799072,
      "learning_rate": 3.856424e-05,
      "loss": 0.2092,
      "step": 143000
    },
    {
      "epoch": 23.04,
      "grad_norm": 1.6808077096939087,
      "learning_rate": 3.848432e-05,
      "loss": 0.2002,
      "step": 144000
    },
    {
      "epoch": 23.2,
      "grad_norm": 1.2995768785476685,
      "learning_rate": 3.840432e-05,
      "loss": 0.1793,
      "step": 145000
    },
    {
      "epoch": 23.36,
      "grad_norm": 1.6490942239761353,
      "learning_rate": 3.83244e-05,
      "loss": 0.1868,
      "step": 146000
    },
    {
      "epoch": 23.52,
      "grad_norm": 1.1707346439361572,
      "learning_rate": 3.824448e-05,
      "loss": 0.1838,
      "step": 147000
    },
    {
      "epoch": 23.68,
      "grad_norm": 3.6107177734375,
      "learning_rate": 3.816448e-05,
      "loss": 0.183,
      "step": 148000
    },
    {
      "epoch": 23.84,
      "grad_norm": 2.3001925945281982,
      "learning_rate": 3.808448e-05,
      "loss": 0.1888,
      "step": 149000
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.25855356454849243,
      "learning_rate": 3.8004480000000004e-05,
      "loss": 0.1974,
      "step": 150000
    },
    {
      "epoch": 24.16,
      "grad_norm": 2.08726167678833,
      "learning_rate": 3.792456e-05,
      "loss": 0.1663,
      "step": 151000
    },
    {
      "epoch": 24.32,
      "grad_norm": 1.0343971252441406,
      "learning_rate": 3.7844560000000004e-05,
      "loss": 0.169,
      "step": 152000
    },
    {
      "epoch": 24.48,
      "grad_norm": 1.5230445861816406,
      "learning_rate": 3.7764560000000005e-05,
      "loss": 0.1686,
      "step": 153000
    },
    {
      "epoch": 24.64,
      "grad_norm": 1.0436009168624878,
      "learning_rate": 3.7684640000000004e-05,
      "loss": 0.1727,
      "step": 154000
    },
    {
      "epoch": 24.8,
      "grad_norm": 1.3265231847763062,
      "learning_rate": 3.7604640000000005e-05,
      "loss": 0.1692,
      "step": 155000
    },
    {
      "epoch": 24.96,
      "grad_norm": 0.9974834322929382,
      "learning_rate": 3.7524720000000005e-05,
      "loss": 0.175,
      "step": 156000
    },
    {
      "epoch": 25.12,
      "grad_norm": 1.108629822731018,
      "learning_rate": 3.7444800000000004e-05,
      "loss": 0.1539,
      "step": 157000
    },
    {
      "epoch": 25.28,
      "grad_norm": 2.0849668979644775,
      "learning_rate": 3.73648e-05,
      "loss": 0.1541,
      "step": 158000
    },
    {
      "epoch": 25.44,
      "grad_norm": 1.1615557670593262,
      "learning_rate": 3.7284800000000006e-05,
      "loss": 0.1524,
      "step": 159000
    },
    {
      "epoch": 25.6,
      "grad_norm": 1.6431320905685425,
      "learning_rate": 3.72048e-05,
      "loss": 0.1562,
      "step": 160000
    },
    {
      "epoch": 25.76,
      "grad_norm": 1.9557209014892578,
      "learning_rate": 3.712488e-05,
      "loss": 0.1618,
      "step": 161000
    },
    {
      "epoch": 25.92,
      "grad_norm": 2.5582704544067383,
      "learning_rate": 3.704488000000001e-05,
      "loss": 0.1576,
      "step": 162000
    },
    {
      "epoch": 26.08,
      "grad_norm": 1.1828882694244385,
      "learning_rate": 3.696488e-05,
      "loss": 0.1518,
      "step": 163000
    },
    {
      "epoch": 26.24,
      "grad_norm": 0.6018717885017395,
      "learning_rate": 3.688488e-05,
      "loss": 0.1386,
      "step": 164000
    },
    {
      "epoch": 26.4,
      "grad_norm": 1.4065035581588745,
      "learning_rate": 3.680488e-05,
      "loss": 0.1397,
      "step": 165000
    },
    {
      "epoch": 26.56,
      "grad_norm": 1.156138300895691,
      "learning_rate": 3.672496e-05,
      "loss": 0.1437,
      "step": 166000
    },
    {
      "epoch": 26.72,
      "grad_norm": 1.4126169681549072,
      "learning_rate": 3.664496e-05,
      "loss": 0.142,
      "step": 167000
    },
    {
      "epoch": 26.88,
      "grad_norm": 1.1978753805160522,
      "learning_rate": 3.656504e-05,
      "loss": 0.1528,
      "step": 168000
    },
    {
      "epoch": 27.04,
      "grad_norm": 1.074002742767334,
      "learning_rate": 3.648504e-05,
      "loss": 0.1401,
      "step": 169000
    },
    {
      "epoch": 27.2,
      "grad_norm": 1.6367994546890259,
      "learning_rate": 3.640512e-05,
      "loss": 0.1281,
      "step": 170000
    },
    {
      "epoch": 27.36,
      "grad_norm": 1.1997789144515991,
      "learning_rate": 3.6325120000000004e-05,
      "loss": 0.1272,
      "step": 171000
    },
    {
      "epoch": 27.52,
      "grad_norm": 1.5879887342453003,
      "learning_rate": 3.624512e-05,
      "loss": 0.1308,
      "step": 172000
    },
    {
      "epoch": 27.68,
      "grad_norm": 5.412214756011963,
      "learning_rate": 3.6165120000000005e-05,
      "loss": 0.1334,
      "step": 173000
    },
    {
      "epoch": 27.84,
      "grad_norm": 1.2990578413009644,
      "learning_rate": 3.6085200000000005e-05,
      "loss": 0.1343,
      "step": 174000
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.5833780765533447,
      "learning_rate": 3.60052e-05,
      "loss": 0.1417,
      "step": 175000
    },
    {
      "epoch": 28.16,
      "grad_norm": 1.1409436464309692,
      "learning_rate": 3.592528e-05,
      "loss": 0.1175,
      "step": 176000
    },
    {
      "epoch": 28.32,
      "grad_norm": 1.157383680343628,
      "learning_rate": 3.584536e-05,
      "loss": 0.1193,
      "step": 177000
    },
    {
      "epoch": 28.48,
      "grad_norm": 1.302846074104309,
      "learning_rate": 3.5765360000000005e-05,
      "loss": 0.1178,
      "step": 178000
    },
    {
      "epoch": 28.64,
      "grad_norm": 1.2643346786499023,
      "learning_rate": 3.568536e-05,
      "loss": 0.1217,
      "step": 179000
    },
    {
      "epoch": 28.8,
      "grad_norm": 1.2578614950180054,
      "learning_rate": 3.560536000000001e-05,
      "loss": 0.1276,
      "step": 180000
    },
    {
      "epoch": 28.96,
      "grad_norm": 0.29727038741111755,
      "learning_rate": 3.5525440000000007e-05,
      "loss": 0.128,
      "step": 181000
    },
    {
      "epoch": 29.12,
      "grad_norm": 0.5517187714576721,
      "learning_rate": 3.544544e-05,
      "loss": 0.1133,
      "step": 182000
    },
    {
      "epoch": 29.28,
      "grad_norm": 0.7468270659446716,
      "learning_rate": 3.536552e-05,
      "loss": 0.1107,
      "step": 183000
    },
    {
      "epoch": 29.44,
      "grad_norm": 4.57526969909668,
      "learning_rate": 3.52856e-05,
      "loss": 0.1062,
      "step": 184000
    },
    {
      "epoch": 29.6,
      "grad_norm": 0.8830690383911133,
      "learning_rate": 3.52056e-05,
      "loss": 0.1134,
      "step": 185000
    },
    {
      "epoch": 29.76,
      "grad_norm": 0.807873010635376,
      "learning_rate": 3.51256e-05,
      "loss": 0.1159,
      "step": 186000
    },
    {
      "epoch": 29.92,
      "grad_norm": 1.3864738941192627,
      "learning_rate": 3.504568e-05,
      "loss": 0.1197,
      "step": 187000
    },
    {
      "epoch": 30.08,
      "grad_norm": 1.3619606494903564,
      "learning_rate": 3.496568e-05,
      "loss": 0.1105,
      "step": 188000
    },
    {
      "epoch": 30.24,
      "grad_norm": 1.2556315660476685,
      "learning_rate": 3.488576e-05,
      "loss": 0.1006,
      "step": 189000
    },
    {
      "epoch": 30.4,
      "grad_norm": 1.6073418855667114,
      "learning_rate": 3.480576e-05,
      "loss": 0.1009,
      "step": 190000
    },
    {
      "epoch": 30.56,
      "grad_norm": 0.7049980759620667,
      "learning_rate": 3.472576e-05,
      "loss": 0.1071,
      "step": 191000
    },
    {
      "epoch": 30.72,
      "grad_norm": 0.811836838722229,
      "learning_rate": 3.464584e-05,
      "loss": 0.1103,
      "step": 192000
    },
    {
      "epoch": 30.88,
      "grad_norm": 1.6366041898727417,
      "learning_rate": 3.4565839999999996e-05,
      "loss": 0.111,
      "step": 193000
    },
    {
      "epoch": 31.04,
      "grad_norm": 0.6816107630729675,
      "learning_rate": 3.448592e-05,
      "loss": 0.1057,
      "step": 194000
    },
    {
      "epoch": 31.2,
      "grad_norm": 0.5955324769020081,
      "learning_rate": 3.4405920000000003e-05,
      "loss": 0.0926,
      "step": 195000
    },
    {
      "epoch": 31.36,
      "grad_norm": 0.7549210786819458,
      "learning_rate": 3.432592e-05,
      "loss": 0.0935,
      "step": 196000
    },
    {
      "epoch": 31.52,
      "grad_norm": 1.577593445777893,
      "learning_rate": 3.4245920000000005e-05,
      "loss": 0.0949,
      "step": 197000
    },
    {
      "epoch": 31.68,
      "grad_norm": Infinity,
      "learning_rate": 3.4166000000000005e-05,
      "loss": 0.0989,
      "step": 198000
    },
    {
      "epoch": 31.84,
      "grad_norm": 1.8476159572601318,
      "learning_rate": 3.4086e-05,
      "loss": 0.1048,
      "step": 199000
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.9109454154968262,
      "learning_rate": 3.400608e-05,
      "loss": 0.1061,
      "step": 200000
    },
    {
      "epoch": 32.16,
      "grad_norm": 1.6235361099243164,
      "learning_rate": 3.392608e-05,
      "loss": 0.0858,
      "step": 201000
    },
    {
      "epoch": 32.32,
      "grad_norm": 1.6188963651657104,
      "learning_rate": 3.384608e-05,
      "loss": 0.0853,
      "step": 202000
    },
    {
      "epoch": 32.48,
      "grad_norm": 0.4720228910446167,
      "learning_rate": 3.376616e-05,
      "loss": 0.0894,
      "step": 203000
    },
    {
      "epoch": 32.64,
      "grad_norm": 0.9789763689041138,
      "learning_rate": 3.368616e-05,
      "loss": 0.0906,
      "step": 204000
    },
    {
      "epoch": 32.8,
      "grad_norm": 0.2087625116109848,
      "learning_rate": 3.360616e-05,
      "loss": 0.0946,
      "step": 205000
    },
    {
      "epoch": 32.96,
      "grad_norm": 0.8154292106628418,
      "learning_rate": 3.352616e-05,
      "loss": 0.1008,
      "step": 206000
    },
    {
      "epoch": 33.12,
      "grad_norm": 1.3843892812728882,
      "learning_rate": 3.344632e-05,
      "loss": 0.0864,
      "step": 207000
    },
    {
      "epoch": 33.28,
      "grad_norm": 0.5712646245956421,
      "learning_rate": 3.336632e-05,
      "loss": 0.0815,
      "step": 208000
    },
    {
      "epoch": 33.44,
      "grad_norm": 0.2597731053829193,
      "learning_rate": 3.328632e-05,
      "loss": 0.0829,
      "step": 209000
    },
    {
      "epoch": 33.6,
      "grad_norm": 5.405902862548828,
      "learning_rate": 3.32064e-05,
      "loss": 0.0838,
      "step": 210000
    },
    {
      "epoch": 33.76,
      "grad_norm": 0.9014701843261719,
      "learning_rate": 3.31264e-05,
      "loss": 0.0883,
      "step": 211000
    },
    {
      "epoch": 33.92,
      "grad_norm": 0.36315691471099854,
      "learning_rate": 3.30464e-05,
      "loss": 0.091,
      "step": 212000
    },
    {
      "epoch": 34.08,
      "grad_norm": 2.1986899375915527,
      "learning_rate": 3.296648e-05,
      "loss": 0.0823,
      "step": 213000
    },
    {
      "epoch": 34.24,
      "grad_norm": 0.7489439249038696,
      "learning_rate": 3.288648e-05,
      "loss": 0.0764,
      "step": 214000
    },
    {
      "epoch": 34.4,
      "grad_norm": 0.9121980667114258,
      "learning_rate": 3.2806480000000004e-05,
      "loss": 0.0785,
      "step": 215000
    },
    {
      "epoch": 34.56,
      "grad_norm": 1.037151575088501,
      "learning_rate": 3.2726480000000005e-05,
      "loss": 0.0817,
      "step": 216000
    },
    {
      "epoch": 34.72,
      "grad_norm": 1.1304656267166138,
      "learning_rate": 3.264664e-05,
      "loss": 0.0815,
      "step": 217000
    },
    {
      "epoch": 34.88,
      "grad_norm": 0.9127541184425354,
      "learning_rate": 3.2566640000000004e-05,
      "loss": 0.0833,
      "step": 218000
    },
    {
      "epoch": 35.04,
      "grad_norm": 1.2460005283355713,
      "learning_rate": 3.248672e-05,
      "loss": 0.0875,
      "step": 219000
    },
    {
      "epoch": 35.2,
      "grad_norm": 2.034369707107544,
      "learning_rate": 3.2406720000000004e-05,
      "loss": 0.0692,
      "step": 220000
    },
    {
      "epoch": 35.36,
      "grad_norm": 0.8008579611778259,
      "learning_rate": 3.232672e-05,
      "loss": 0.0736,
      "step": 221000
    },
    {
      "epoch": 35.52,
      "grad_norm": 1.1672395467758179,
      "learning_rate": 3.2246720000000006e-05,
      "loss": 0.0713,
      "step": 222000
    },
    {
      "epoch": 35.68,
      "grad_norm": 1.2040226459503174,
      "learning_rate": 3.2166800000000005e-05,
      "loss": 0.0789,
      "step": 223000
    },
    {
      "epoch": 35.84,
      "grad_norm": 1.2131556272506714,
      "learning_rate": 3.2086880000000005e-05,
      "loss": 0.0791,
      "step": 224000
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.637217104434967,
      "learning_rate": 3.200688e-05,
      "loss": 0.0818,
      "step": 225000
    },
    {
      "epoch": 36.16,
      "grad_norm": 0.06950975209474564,
      "learning_rate": 3.192696e-05,
      "loss": 0.0688,
      "step": 226000
    },
    {
      "epoch": 36.32,
      "grad_norm": 1.001017451286316,
      "learning_rate": 3.1846960000000006e-05,
      "loss": 0.0645,
      "step": 227000
    },
    {
      "epoch": 36.48,
      "grad_norm": 1.900303602218628,
      "learning_rate": 3.176696e-05,
      "loss": 0.0718,
      "step": 228000
    },
    {
      "epoch": 36.64,
      "grad_norm": 0.6846794486045837,
      "learning_rate": 3.168704e-05,
      "loss": 0.0683,
      "step": 229000
    },
    {
      "epoch": 36.8,
      "grad_norm": 0.41367679834365845,
      "learning_rate": 3.160704e-05,
      "loss": 0.0716,
      "step": 230000
    },
    {
      "epoch": 36.96,
      "grad_norm": 0.4602726995944977,
      "learning_rate": 3.152704e-05,
      "loss": 0.0777,
      "step": 231000
    },
    {
      "epoch": 37.12,
      "grad_norm": 0.8680228590965271,
      "learning_rate": 3.144712e-05,
      "loss": 0.0693,
      "step": 232000
    },
    {
      "epoch": 37.28,
      "grad_norm": 0.41711199283599854,
      "learning_rate": 3.136712e-05,
      "loss": 0.0607,
      "step": 233000
    },
    {
      "epoch": 37.44,
      "grad_norm": 1.0282554626464844,
      "learning_rate": 3.12872e-05,
      "loss": 0.0651,
      "step": 234000
    },
    {
      "epoch": 37.6,
      "grad_norm": 0.08176454156637192,
      "learning_rate": 3.12072e-05,
      "loss": 0.0676,
      "step": 235000
    },
    {
      "epoch": 37.76,
      "grad_norm": 0.7596827149391174,
      "learning_rate": 3.11272e-05,
      "loss": 0.0697,
      "step": 236000
    },
    {
      "epoch": 37.92,
      "grad_norm": 0.8078145980834961,
      "learning_rate": 3.104728e-05,
      "loss": 0.0723,
      "step": 237000
    },
    {
      "epoch": 38.08,
      "grad_norm": 4.014986991882324,
      "learning_rate": 3.096728e-05,
      "loss": 0.0656,
      "step": 238000
    },
    {
      "epoch": 38.24,
      "grad_norm": 0.9003351330757141,
      "learning_rate": 3.0887280000000004e-05,
      "loss": 0.0591,
      "step": 239000
    },
    {
      "epoch": 38.4,
      "grad_norm": 1.3161089420318604,
      "learning_rate": 3.080736e-05,
      "loss": 0.061,
      "step": 240000
    },
    {
      "epoch": 38.56,
      "grad_norm": 0.23469850420951843,
      "learning_rate": 3.072736e-05,
      "loss": 0.0627,
      "step": 241000
    },
    {
      "epoch": 38.72,
      "grad_norm": 2.907910108566284,
      "learning_rate": 3.064744e-05,
      "loss": 0.0623,
      "step": 242000
    },
    {
      "epoch": 38.88,
      "grad_norm": 0.058799393475055695,
      "learning_rate": 3.0567440000000004e-05,
      "loss": 0.0693,
      "step": 243000
    },
    {
      "epoch": 39.04,
      "grad_norm": 0.9041770696640015,
      "learning_rate": 3.048744e-05,
      "loss": 0.0687,
      "step": 244000
    },
    {
      "epoch": 39.2,
      "grad_norm": 1.1167824268341064,
      "learning_rate": 3.0407440000000002e-05,
      "loss": 0.0567,
      "step": 245000
    },
    {
      "epoch": 39.36,
      "grad_norm": 0.945584774017334,
      "learning_rate": 3.0327520000000005e-05,
      "loss": 0.0565,
      "step": 246000
    },
    {
      "epoch": 39.52,
      "grad_norm": 1.3546926975250244,
      "learning_rate": 3.0247520000000003e-05,
      "loss": 0.0568,
      "step": 247000
    },
    {
      "epoch": 39.68,
      "grad_norm": 0.5685890913009644,
      "learning_rate": 3.0167600000000002e-05,
      "loss": 0.0605,
      "step": 248000
    },
    {
      "epoch": 39.84,
      "grad_norm": 0.8513118624687195,
      "learning_rate": 3.00876e-05,
      "loss": 0.0628,
      "step": 249000
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.6272323131561279,
      "learning_rate": 3.000768e-05,
      "loss": 0.0678,
      "step": 250000
    },
    {
      "epoch": 40.16,
      "grad_norm": 0.691657543182373,
      "learning_rate": 2.992776e-05,
      "loss": 0.0534,
      "step": 251000
    },
    {
      "epoch": 40.32,
      "grad_norm": 6.736340045928955,
      "learning_rate": 2.9847760000000003e-05,
      "loss": 0.0529,
      "step": 252000
    },
    {
      "epoch": 40.48,
      "grad_norm": 1.1875168085098267,
      "learning_rate": 2.9767840000000003e-05,
      "loss": 0.055,
      "step": 253000
    },
    {
      "epoch": 40.64,
      "grad_norm": 0.6789680123329163,
      "learning_rate": 2.968784e-05,
      "loss": 0.0563,
      "step": 254000
    },
    {
      "epoch": 40.8,
      "grad_norm": 2.101308822631836,
      "learning_rate": 2.9607840000000004e-05,
      "loss": 0.0618,
      "step": 255000
    },
    {
      "epoch": 40.96,
      "grad_norm": 0.8581178188323975,
      "learning_rate": 2.952784e-05,
      "loss": 0.0625,
      "step": 256000
    },
    {
      "epoch": 41.12,
      "grad_norm": 0.17974348366260529,
      "learning_rate": 2.944792e-05,
      "loss": 0.0509,
      "step": 257000
    },
    {
      "epoch": 41.28,
      "grad_norm": 1.176606297492981,
      "learning_rate": 2.9368e-05,
      "loss": 0.0543,
      "step": 258000
    },
    {
      "epoch": 41.44,
      "grad_norm": 0.5381352305412292,
      "learning_rate": 2.9287999999999998e-05,
      "loss": 0.0517,
      "step": 259000
    },
    {
      "epoch": 41.6,
      "grad_norm": 0.7916551232337952,
      "learning_rate": 2.9208000000000002e-05,
      "loss": 0.0519,
      "step": 260000
    },
    {
      "epoch": 41.76,
      "grad_norm": 1.5209778547286987,
      "learning_rate": 2.9128e-05,
      "loss": 0.0561,
      "step": 261000
    },
    {
      "epoch": 41.92,
      "grad_norm": 0.4323720932006836,
      "learning_rate": 2.904808e-05,
      "loss": 0.0592,
      "step": 262000
    },
    {
      "epoch": 42.08,
      "grad_norm": 1.0767817497253418,
      "learning_rate": 2.8968080000000003e-05,
      "loss": 0.0561,
      "step": 263000
    },
    {
      "epoch": 42.24,
      "grad_norm": 0.27533242106437683,
      "learning_rate": 2.888808e-05,
      "loss": 0.0444,
      "step": 264000
    },
    {
      "epoch": 42.4,
      "grad_norm": 0.2804078459739685,
      "learning_rate": 2.8808080000000005e-05,
      "loss": 0.0468,
      "step": 265000
    },
    {
      "epoch": 42.56,
      "grad_norm": 0.6311641335487366,
      "learning_rate": 2.8728160000000004e-05,
      "loss": 0.0497,
      "step": 266000
    },
    {
      "epoch": 42.72,
      "grad_norm": 0.8488089442253113,
      "learning_rate": 2.8648160000000002e-05,
      "loss": 0.0545,
      "step": 267000
    },
    {
      "epoch": 42.88,
      "grad_norm": 2.9620771408081055,
      "learning_rate": 2.856824e-05,
      "loss": 0.0544,
      "step": 268000
    },
    {
      "epoch": 43.04,
      "grad_norm": 0.8226404786109924,
      "learning_rate": 2.848824e-05,
      "loss": 0.0555,
      "step": 269000
    },
    {
      "epoch": 43.2,
      "grad_norm": 0.24383904039859772,
      "learning_rate": 2.8408240000000003e-05,
      "loss": 0.0455,
      "step": 270000
    },
    {
      "epoch": 43.36,
      "grad_norm": 0.18584711849689484,
      "learning_rate": 2.832824e-05,
      "loss": 0.0462,
      "step": 271000
    },
    {
      "epoch": 43.52,
      "grad_norm": 0.9976147413253784,
      "learning_rate": 2.8248400000000002e-05,
      "loss": 0.047,
      "step": 272000
    },
    {
      "epoch": 43.68,
      "grad_norm": 1.2132201194763184,
      "learning_rate": 2.81684e-05,
      "loss": 0.0498,
      "step": 273000
    },
    {
      "epoch": 43.84,
      "grad_norm": 0.7158915996551514,
      "learning_rate": 2.8088400000000004e-05,
      "loss": 0.0521,
      "step": 274000
    },
    {
      "epoch": 44.0,
      "grad_norm": 2.380197525024414,
      "learning_rate": 2.80084e-05,
      "loss": 0.0546,
      "step": 275000
    },
    {
      "epoch": 44.16,
      "grad_norm": 0.7539950013160706,
      "learning_rate": 2.7928560000000003e-05,
      "loss": 0.042,
      "step": 276000
    },
    {
      "epoch": 44.32,
      "grad_norm": 0.24447636306285858,
      "learning_rate": 2.784856e-05,
      "loss": 0.0434,
      "step": 277000
    },
    {
      "epoch": 44.48,
      "grad_norm": 1.0154505968093872,
      "learning_rate": 2.7768559999999998e-05,
      "loss": 0.0449,
      "step": 278000
    },
    {
      "epoch": 44.64,
      "grad_norm": 0.7732965350151062,
      "learning_rate": 2.768864e-05,
      "loss": 0.0458,
      "step": 279000
    },
    {
      "epoch": 44.8,
      "grad_norm": 1.1165530681610107,
      "learning_rate": 2.760864e-05,
      "loss": 0.0489,
      "step": 280000
    },
    {
      "epoch": 44.96,
      "grad_norm": 1.812178134918213,
      "learning_rate": 2.752864e-05,
      "loss": 0.0518,
      "step": 281000
    },
    {
      "epoch": 45.12,
      "grad_norm": 0.7663596868515015,
      "learning_rate": 2.7448640000000003e-05,
      "loss": 0.0435,
      "step": 282000
    },
    {
      "epoch": 45.28,
      "grad_norm": 0.054382018744945526,
      "learning_rate": 2.7368720000000002e-05,
      "loss": 0.0398,
      "step": 283000
    },
    {
      "epoch": 45.44,
      "grad_norm": 0.9799361228942871,
      "learning_rate": 2.728872e-05,
      "loss": 0.0451,
      "step": 284000
    },
    {
      "epoch": 45.6,
      "grad_norm": 1.2489068508148193,
      "learning_rate": 2.72088e-05,
      "loss": 0.0447,
      "step": 285000
    },
    {
      "epoch": 45.76,
      "grad_norm": 0.7353442907333374,
      "learning_rate": 2.7128880000000002e-05,
      "loss": 0.0464,
      "step": 286000
    },
    {
      "epoch": 45.92,
      "grad_norm": 0.01947121135890484,
      "learning_rate": 2.704888e-05,
      "loss": 0.049,
      "step": 287000
    },
    {
      "epoch": 46.08,
      "grad_norm": 1.2990872859954834,
      "learning_rate": 2.696896e-05,
      "loss": 0.0433,
      "step": 288000
    },
    {
      "epoch": 46.24,
      "grad_norm": 0.505401611328125,
      "learning_rate": 2.6888960000000004e-05,
      "loss": 0.0384,
      "step": 289000
    },
    {
      "epoch": 46.4,
      "grad_norm": 0.9410567879676819,
      "learning_rate": 2.680896e-05,
      "loss": 0.0387,
      "step": 290000
    },
    {
      "epoch": 46.56,
      "grad_norm": 1.0577404499053955,
      "learning_rate": 2.672896e-05,
      "loss": 0.0438,
      "step": 291000
    },
    {
      "epoch": 46.72,
      "grad_norm": 1.204200267791748,
      "learning_rate": 2.664912e-05,
      "loss": 0.0435,
      "step": 292000
    },
    {
      "epoch": 46.88,
      "grad_norm": 0.576180100440979,
      "learning_rate": 2.6569120000000004e-05,
      "loss": 0.044,
      "step": 293000
    },
    {
      "epoch": 47.04,
      "grad_norm": 0.8789231777191162,
      "learning_rate": 2.648912e-05,
      "loss": 0.0453,
      "step": 294000
    },
    {
      "epoch": 47.2,
      "grad_norm": 1.1651942729949951,
      "learning_rate": 2.6409120000000002e-05,
      "loss": 0.0355,
      "step": 295000
    },
    {
      "epoch": 47.36,
      "grad_norm": 1.0294981002807617,
      "learning_rate": 2.6329200000000005e-05,
      "loss": 0.0408,
      "step": 296000
    },
    {
      "epoch": 47.52,
      "grad_norm": 1.332841396331787,
      "learning_rate": 2.6249200000000003e-05,
      "loss": 0.0378,
      "step": 297000
    },
    {
      "epoch": 47.68,
      "grad_norm": 1.1263527870178223,
      "learning_rate": 2.61692e-05,
      "loss": 0.0424,
      "step": 298000
    },
    {
      "epoch": 47.84,
      "grad_norm": 0.9510263800621033,
      "learning_rate": 2.60892e-05,
      "loss": 0.0436,
      "step": 299000
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.8494783639907837,
      "learning_rate": 2.6009280000000004e-05,
      "loss": 0.0447,
      "step": 300000
    },
    {
      "epoch": 48.16,
      "grad_norm": 0.7954149842262268,
      "learning_rate": 2.592928e-05,
      "loss": 0.0337,
      "step": 301000
    },
    {
      "epoch": 48.32,
      "grad_norm": 0.017110323533415794,
      "learning_rate": 2.584936e-05,
      "loss": 0.0357,
      "step": 302000
    },
    {
      "epoch": 48.48,
      "grad_norm": 0.5722625851631165,
      "learning_rate": 2.5769360000000005e-05,
      "loss": 0.0371,
      "step": 303000
    },
    {
      "epoch": 48.64,
      "grad_norm": 0.9315446019172668,
      "learning_rate": 2.568952e-05,
      "loss": 0.04,
      "step": 304000
    },
    {
      "epoch": 48.8,
      "grad_norm": 0.1540834605693817,
      "learning_rate": 2.5609520000000004e-05,
      "loss": 0.0421,
      "step": 305000
    },
    {
      "epoch": 48.96,
      "grad_norm": 1.1654037237167358,
      "learning_rate": 2.552952e-05,
      "loss": 0.0438,
      "step": 306000
    },
    {
      "epoch": 49.12,
      "grad_norm": 1.1424850225448608,
      "learning_rate": 2.54496e-05,
      "loss": 0.0373,
      "step": 307000
    },
    {
      "epoch": 49.28,
      "grad_norm": 2.591914176940918,
      "learning_rate": 2.53696e-05,
      "loss": 0.0346,
      "step": 308000
    },
    {
      "epoch": 49.44,
      "grad_norm": 0.36707377433776855,
      "learning_rate": 2.5289600000000003e-05,
      "loss": 0.0353,
      "step": 309000
    },
    {
      "epoch": 49.6,
      "grad_norm": 1.207075595855713,
      "learning_rate": 2.52096e-05,
      "loss": 0.0339,
      "step": 310000
    },
    {
      "epoch": 49.76,
      "grad_norm": 1.0065408945083618,
      "learning_rate": 2.512968e-05,
      "loss": 0.039,
      "step": 311000
    },
    {
      "epoch": 49.92,
      "grad_norm": 0.5067104697227478,
      "learning_rate": 2.5049680000000004e-05,
      "loss": 0.0417,
      "step": 312000
    },
    {
      "epoch": 50.08,
      "grad_norm": 0.6512526273727417,
      "learning_rate": 2.496976e-05,
      "loss": 0.0378,
      "step": 313000
    },
    {
      "epoch": 50.24,
      "grad_norm": 0.427951842546463,
      "learning_rate": 2.488976e-05,
      "loss": 0.0318,
      "step": 314000
    },
    {
      "epoch": 50.4,
      "grad_norm": 0.567338764667511,
      "learning_rate": 2.480984e-05,
      "loss": 0.0346,
      "step": 315000
    },
    {
      "epoch": 50.56,
      "grad_norm": 0.11612612754106522,
      "learning_rate": 2.472984e-05,
      "loss": 0.0331,
      "step": 316000
    },
    {
      "epoch": 50.72,
      "grad_norm": 0.9361208081245422,
      "learning_rate": 2.4649840000000002e-05,
      "loss": 0.0374,
      "step": 317000
    },
    {
      "epoch": 50.88,
      "grad_norm": 0.139807790517807,
      "learning_rate": 2.456992e-05,
      "loss": 0.038,
      "step": 318000
    },
    {
      "epoch": 51.04,
      "grad_norm": 0.12519241869449615,
      "learning_rate": 2.4489920000000002e-05,
      "loss": 0.0374,
      "step": 319000
    },
    {
      "epoch": 51.2,
      "grad_norm": 0.1598871350288391,
      "learning_rate": 2.4410000000000002e-05,
      "loss": 0.0317,
      "step": 320000
    },
    {
      "epoch": 51.36,
      "grad_norm": 0.7614963054656982,
      "learning_rate": 2.433e-05,
      "loss": 0.0318,
      "step": 321000
    },
    {
      "epoch": 51.52,
      "grad_norm": 1.3077951669692993,
      "learning_rate": 2.425e-05,
      "loss": 0.0329,
      "step": 322000
    },
    {
      "epoch": 51.68,
      "grad_norm": 0.8043985366821289,
      "learning_rate": 2.417e-05,
      "loss": 0.0328,
      "step": 323000
    },
    {
      "epoch": 51.84,
      "grad_norm": 0.35526108741760254,
      "learning_rate": 2.409008e-05,
      "loss": 0.037,
      "step": 324000
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.1792493760585785,
      "learning_rate": 2.401016e-05,
      "loss": 0.0395,
      "step": 325000
    },
    {
      "epoch": 52.16,
      "grad_norm": 0.4475148916244507,
      "learning_rate": 2.393016e-05,
      "loss": 0.0301,
      "step": 326000
    },
    {
      "epoch": 52.32,
      "grad_norm": 0.5102652907371521,
      "learning_rate": 2.385016e-05,
      "loss": 0.0286,
      "step": 327000
    },
    {
      "epoch": 52.48,
      "grad_norm": 0.07249413430690765,
      "learning_rate": 2.3770160000000002e-05,
      "loss": 0.0313,
      "step": 328000
    },
    {
      "epoch": 52.64,
      "grad_norm": 2.7079989910125732,
      "learning_rate": 2.3690240000000002e-05,
      "loss": 0.033,
      "step": 329000
    },
    {
      "epoch": 52.8,
      "grad_norm": 0.6914011240005493,
      "learning_rate": 2.361024e-05,
      "loss": 0.0356,
      "step": 330000
    },
    {
      "epoch": 52.96,
      "grad_norm": 0.3073476254940033,
      "learning_rate": 2.353032e-05,
      "loss": 0.0365,
      "step": 331000
    },
    {
      "epoch": 53.12,
      "grad_norm": 0.3936142921447754,
      "learning_rate": 2.345032e-05,
      "loss": 0.0301,
      "step": 332000
    },
    {
      "epoch": 53.28,
      "grad_norm": 0.4641056954860687,
      "learning_rate": 2.337032e-05,
      "loss": 0.0301,
      "step": 333000
    },
    {
      "epoch": 53.44,
      "grad_norm": 1.2018471956253052,
      "learning_rate": 2.329032e-05,
      "loss": 0.0298,
      "step": 334000
    },
    {
      "epoch": 53.6,
      "grad_norm": 1.7015503644943237,
      "learning_rate": 2.3210480000000003e-05,
      "loss": 0.0306,
      "step": 335000
    },
    {
      "epoch": 53.76,
      "grad_norm": 1.2461258172988892,
      "learning_rate": 2.313048e-05,
      "loss": 0.0334,
      "step": 336000
    },
    {
      "epoch": 53.92,
      "grad_norm": 0.09387731552124023,
      "learning_rate": 2.305048e-05,
      "loss": 0.0322,
      "step": 337000
    },
    {
      "epoch": 54.08,
      "grad_norm": 0.6936349272727966,
      "learning_rate": 2.297056e-05,
      "loss": 0.0297,
      "step": 338000
    },
    {
      "epoch": 54.24,
      "grad_norm": 1.6031467914581299,
      "learning_rate": 2.289056e-05,
      "loss": 0.0269,
      "step": 339000
    },
    {
      "epoch": 54.4,
      "grad_norm": 4.107934474945068,
      "learning_rate": 2.281056e-05,
      "loss": 0.0295,
      "step": 340000
    },
    {
      "epoch": 54.56,
      "grad_norm": 0.7917604446411133,
      "learning_rate": 2.273056e-05,
      "loss": 0.0301,
      "step": 341000
    },
    {
      "epoch": 54.72,
      "grad_norm": 0.019657541066408157,
      "learning_rate": 2.2650640000000002e-05,
      "loss": 0.0305,
      "step": 342000
    },
    {
      "epoch": 54.88,
      "grad_norm": 0.26895248889923096,
      "learning_rate": 2.257064e-05,
      "loss": 0.0327,
      "step": 343000
    },
    {
      "epoch": 55.04,
      "grad_norm": 0.39725780487060547,
      "learning_rate": 2.249064e-05,
      "loss": 0.0323,
      "step": 344000
    },
    {
      "epoch": 55.2,
      "grad_norm": 0.3822101652622223,
      "learning_rate": 2.241064e-05,
      "loss": 0.0276,
      "step": 345000
    },
    {
      "epoch": 55.36,
      "grad_norm": 0.988732635974884,
      "learning_rate": 2.2330800000000003e-05,
      "loss": 0.0279,
      "step": 346000
    },
    {
      "epoch": 55.52,
      "grad_norm": 0.10756540298461914,
      "learning_rate": 2.2250800000000004e-05,
      "loss": 0.028,
      "step": 347000
    },
    {
      "epoch": 55.68,
      "grad_norm": 0.3030531108379364,
      "learning_rate": 2.21708e-05,
      "loss": 0.0271,
      "step": 348000
    },
    {
      "epoch": 55.84,
      "grad_norm": 0.662106454372406,
      "learning_rate": 2.209088e-05,
      "loss": 0.03,
      "step": 349000
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.8444761633872986,
      "learning_rate": 2.201088e-05,
      "loss": 0.0337,
      "step": 350000
    },
    {
      "epoch": 56.16,
      "grad_norm": 0.3279471695423126,
      "learning_rate": 2.1930880000000002e-05,
      "loss": 0.0247,
      "step": 351000
    },
    {
      "epoch": 56.32,
      "grad_norm": 0.146848663687706,
      "learning_rate": 2.1850960000000002e-05,
      "loss": 0.0256,
      "step": 352000
    },
    {
      "epoch": 56.48,
      "grad_norm": 0.5189355611801147,
      "learning_rate": 2.1770960000000003e-05,
      "loss": 0.0261,
      "step": 353000
    },
    {
      "epoch": 56.64,
      "grad_norm": 1.0961297750473022,
      "learning_rate": 2.1691040000000002e-05,
      "loss": 0.0276,
      "step": 354000
    },
    {
      "epoch": 56.8,
      "grad_norm": 0.24495530128479004,
      "learning_rate": 2.1611040000000003e-05,
      "loss": 0.0285,
      "step": 355000
    },
    {
      "epoch": 56.96,
      "grad_norm": 0.07794257998466492,
      "learning_rate": 2.1531040000000004e-05,
      "loss": 0.032,
      "step": 356000
    },
    {
      "epoch": 57.12,
      "grad_norm": 0.26352256536483765,
      "learning_rate": 2.1451120000000003e-05,
      "loss": 0.0286,
      "step": 357000
    },
    {
      "epoch": 57.28,
      "grad_norm": 0.6485413908958435,
      "learning_rate": 2.137112e-05,
      "loss": 0.0231,
      "step": 358000
    },
    {
      "epoch": 57.44,
      "grad_norm": 0.5845397710800171,
      "learning_rate": 2.129112e-05,
      "loss": 0.027,
      "step": 359000
    },
    {
      "epoch": 57.6,
      "grad_norm": 0.3079392611980438,
      "learning_rate": 2.1211120000000002e-05,
      "loss": 0.0256,
      "step": 360000
    },
    {
      "epoch": 57.76,
      "grad_norm": 1.0105334520339966,
      "learning_rate": 2.1131200000000002e-05,
      "loss": 0.0282,
      "step": 361000
    },
    {
      "epoch": 57.92,
      "grad_norm": 1.7528024911880493,
      "learning_rate": 2.105128e-05,
      "loss": 0.0281,
      "step": 362000
    },
    {
      "epoch": 58.08,
      "grad_norm": 0.8978254199028015,
      "learning_rate": 2.0971280000000002e-05,
      "loss": 0.0269,
      "step": 363000
    },
    {
      "epoch": 58.24,
      "grad_norm": 0.17801515758037567,
      "learning_rate": 2.0891280000000003e-05,
      "loss": 0.0243,
      "step": 364000
    },
    {
      "epoch": 58.4,
      "grad_norm": 1.1586027145385742,
      "learning_rate": 2.0811360000000003e-05,
      "loss": 0.0238,
      "step": 365000
    },
    {
      "epoch": 58.56,
      "grad_norm": 1.6973910331726074,
      "learning_rate": 2.073136e-05,
      "loss": 0.0249,
      "step": 366000
    },
    {
      "epoch": 58.72,
      "grad_norm": 1.2637357711791992,
      "learning_rate": 2.065136e-05,
      "loss": 0.0268,
      "step": 367000
    },
    {
      "epoch": 58.88,
      "grad_norm": 0.07718144357204437,
      "learning_rate": 2.057136e-05,
      "loss": 0.0289,
      "step": 368000
    },
    {
      "epoch": 59.04,
      "grad_norm": 0.3755166232585907,
      "learning_rate": 2.049152e-05,
      "loss": 0.0262,
      "step": 369000
    },
    {
      "epoch": 59.2,
      "grad_norm": 0.1075761690735817,
      "learning_rate": 2.041152e-05,
      "loss": 0.0224,
      "step": 370000
    },
    {
      "epoch": 59.36,
      "grad_norm": 0.987874448299408,
      "learning_rate": 2.03316e-05,
      "loss": 0.023,
      "step": 371000
    },
    {
      "epoch": 59.52,
      "grad_norm": 0.14695234596729279,
      "learning_rate": 2.02516e-05,
      "loss": 0.0247,
      "step": 372000
    },
    {
      "epoch": 59.68,
      "grad_norm": 0.6650362610816956,
      "learning_rate": 2.0171600000000002e-05,
      "loss": 0.0243,
      "step": 373000
    },
    {
      "epoch": 59.84,
      "grad_norm": 0.09016717225313187,
      "learning_rate": 2.009168e-05,
      "loss": 0.0272,
      "step": 374000
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.1669754981994629,
      "learning_rate": 2.0011680000000002e-05,
      "loss": 0.0302,
      "step": 375000
    },
    {
      "epoch": 60.16,
      "grad_norm": 0.8618219494819641,
      "learning_rate": 1.993168e-05,
      "loss": 0.0225,
      "step": 376000
    },
    {
      "epoch": 60.32,
      "grad_norm": 1.278706431388855,
      "learning_rate": 1.985168e-05,
      "loss": 0.0216,
      "step": 377000
    },
    {
      "epoch": 60.48,
      "grad_norm": 0.9474614858627319,
      "learning_rate": 1.977176e-05,
      "loss": 0.024,
      "step": 378000
    },
    {
      "epoch": 60.64,
      "grad_norm": 0.22941797971725464,
      "learning_rate": 1.969176e-05,
      "loss": 0.0232,
      "step": 379000
    },
    {
      "epoch": 60.8,
      "grad_norm": 0.045567456632852554,
      "learning_rate": 1.961184e-05,
      "loss": 0.0254,
      "step": 380000
    },
    {
      "epoch": 60.96,
      "grad_norm": 1.3786348104476929,
      "learning_rate": 1.953184e-05,
      "loss": 0.027,
      "step": 381000
    },
    {
      "epoch": 61.12,
      "grad_norm": 1.046385407447815,
      "learning_rate": 1.9451840000000002e-05,
      "loss": 0.0247,
      "step": 382000
    },
    {
      "epoch": 61.28,
      "grad_norm": 0.7025226950645447,
      "learning_rate": 1.9371840000000003e-05,
      "loss": 0.0214,
      "step": 383000
    },
    {
      "epoch": 61.44,
      "grad_norm": 0.5822115540504456,
      "learning_rate": 1.9291920000000002e-05,
      "loss": 0.0224,
      "step": 384000
    },
    {
      "epoch": 61.6,
      "grad_norm": 0.07651028037071228,
      "learning_rate": 1.9212000000000002e-05,
      "loss": 0.0233,
      "step": 385000
    },
    {
      "epoch": 61.76,
      "grad_norm": 0.05178532749414444,
      "learning_rate": 1.9132e-05,
      "loss": 0.0243,
      "step": 386000
    },
    {
      "epoch": 61.92,
      "grad_norm": 1.0584304332733154,
      "learning_rate": 1.9052e-05,
      "loss": 0.0258,
      "step": 387000
    },
    {
      "epoch": 62.08,
      "grad_norm": 0.1434066742658615,
      "learning_rate": 1.897208e-05,
      "loss": 0.0237,
      "step": 388000
    },
    {
      "epoch": 62.24,
      "grad_norm": 0.09710682183504105,
      "learning_rate": 1.889208e-05,
      "loss": 0.0203,
      "step": 389000
    },
    {
      "epoch": 62.4,
      "grad_norm": 0.7624527215957642,
      "learning_rate": 1.881208e-05,
      "loss": 0.0216,
      "step": 390000
    },
    {
      "epoch": 62.56,
      "grad_norm": 1.0824047327041626,
      "learning_rate": 1.8732080000000002e-05,
      "loss": 0.0222,
      "step": 391000
    },
    {
      "epoch": 62.72,
      "grad_norm": 0.4418151080608368,
      "learning_rate": 1.865224e-05,
      "loss": 0.0231,
      "step": 392000
    },
    {
      "epoch": 62.88,
      "grad_norm": 0.09973613917827606,
      "learning_rate": 1.857224e-05,
      "loss": 0.0236,
      "step": 393000
    },
    {
      "epoch": 63.04,
      "grad_norm": 1.2427059412002563,
      "learning_rate": 1.8492239999999998e-05,
      "loss": 0.025,
      "step": 394000
    },
    {
      "epoch": 63.2,
      "grad_norm": 0.5962896347045898,
      "learning_rate": 1.8412319999999998e-05,
      "loss": 0.0208,
      "step": 395000
    },
    {
      "epoch": 63.36,
      "grad_norm": 0.6542366743087769,
      "learning_rate": 1.833232e-05,
      "loss": 0.0204,
      "step": 396000
    },
    {
      "epoch": 63.52,
      "grad_norm": 0.4341086149215698,
      "learning_rate": 1.825232e-05,
      "loss": 0.0204,
      "step": 397000
    },
    {
      "epoch": 63.68,
      "grad_norm": 0.8357551693916321,
      "learning_rate": 1.817232e-05,
      "loss": 0.0222,
      "step": 398000
    },
    {
      "epoch": 63.84,
      "grad_norm": 0.9446045756340027,
      "learning_rate": 1.80924e-05,
      "loss": 0.0239,
      "step": 399000
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.06299738585948944,
      "learning_rate": 1.80124e-05,
      "loss": 0.0243,
      "step": 400000
    },
    {
      "epoch": 64.16,
      "grad_norm": 0.3538638949394226,
      "learning_rate": 1.793248e-05,
      "loss": 0.0185,
      "step": 401000
    },
    {
      "epoch": 64.32,
      "grad_norm": 0.27636125683784485,
      "learning_rate": 1.785248e-05,
      "loss": 0.0207,
      "step": 402000
    },
    {
      "epoch": 64.48,
      "grad_norm": 0.6439404487609863,
      "learning_rate": 1.7772479999999998e-05,
      "loss": 0.0205,
      "step": 403000
    },
    {
      "epoch": 64.64,
      "grad_norm": 0.0882982462644577,
      "learning_rate": 1.769248e-05,
      "loss": 0.0212,
      "step": 404000
    },
    {
      "epoch": 64.8,
      "grad_norm": 0.7778500318527222,
      "learning_rate": 1.761256e-05,
      "loss": 0.0228,
      "step": 405000
    },
    {
      "epoch": 64.96,
      "grad_norm": 0.8128638863563538,
      "learning_rate": 1.753256e-05,
      "loss": 0.0239,
      "step": 406000
    },
    {
      "epoch": 65.12,
      "grad_norm": 0.201725572347641,
      "learning_rate": 1.745256e-05,
      "loss": 0.0197,
      "step": 407000
    },
    {
      "epoch": 65.28,
      "grad_norm": 0.07506097853183746,
      "learning_rate": 1.737264e-05,
      "loss": 0.0194,
      "step": 408000
    },
    {
      "epoch": 65.44,
      "grad_norm": 0.7845919132232666,
      "learning_rate": 1.729264e-05,
      "loss": 0.0192,
      "step": 409000
    },
    {
      "epoch": 65.6,
      "grad_norm": 0.3048383295536041,
      "learning_rate": 1.721264e-05,
      "loss": 0.0206,
      "step": 410000
    },
    {
      "epoch": 65.76,
      "grad_norm": 0.8481876254081726,
      "learning_rate": 1.713264e-05,
      "loss": 0.0222,
      "step": 411000
    },
    {
      "epoch": 65.92,
      "grad_norm": 0.7867000699043274,
      "learning_rate": 1.7052719999999998e-05,
      "loss": 0.024,
      "step": 412000
    },
    {
      "epoch": 66.08,
      "grad_norm": 0.18603812158107758,
      "learning_rate": 1.697272e-05,
      "loss": 0.0206,
      "step": 413000
    },
    {
      "epoch": 66.24,
      "grad_norm": 0.7332850694656372,
      "learning_rate": 1.689272e-05,
      "loss": 0.0176,
      "step": 414000
    },
    {
      "epoch": 66.4,
      "grad_norm": 0.635423481464386,
      "learning_rate": 1.681272e-05,
      "loss": 0.0194,
      "step": 415000
    },
    {
      "epoch": 66.56,
      "grad_norm": 0.23436491191387177,
      "learning_rate": 1.67328e-05,
      "loss": 0.0192,
      "step": 416000
    },
    {
      "epoch": 66.72,
      "grad_norm": 0.1774505078792572,
      "learning_rate": 1.66528e-05,
      "loss": 0.0214,
      "step": 417000
    },
    {
      "epoch": 66.88,
      "grad_norm": 0.7566232085227966,
      "learning_rate": 1.6572960000000003e-05,
      "loss": 0.0218,
      "step": 418000
    },
    {
      "epoch": 67.04,
      "grad_norm": 2.0881640911102295,
      "learning_rate": 1.649296e-05,
      "loss": 0.0224,
      "step": 419000
    },
    {
      "epoch": 67.2,
      "grad_norm": 0.12557348608970642,
      "learning_rate": 1.641296e-05,
      "loss": 0.0176,
      "step": 420000
    },
    {
      "epoch": 67.36,
      "grad_norm": 0.737862229347229,
      "learning_rate": 1.633304e-05,
      "loss": 0.0182,
      "step": 421000
    },
    {
      "epoch": 67.52,
      "grad_norm": 0.9805861115455627,
      "learning_rate": 1.625304e-05,
      "loss": 0.019,
      "step": 422000
    },
    {
      "epoch": 67.68,
      "grad_norm": 0.8841251134872437,
      "learning_rate": 1.6173040000000002e-05,
      "loss": 0.0203,
      "step": 423000
    },
    {
      "epoch": 67.84,
      "grad_norm": 0.4898845851421356,
      "learning_rate": 1.609304e-05,
      "loss": 0.0199,
      "step": 424000
    },
    {
      "epoch": 68.0,
      "grad_norm": 0.5482001900672913,
      "learning_rate": 1.60132e-05,
      "loss": 0.0234,
      "step": 425000
    },
    {
      "epoch": 68.16,
      "grad_norm": 0.2679452896118164,
      "learning_rate": 1.5933200000000002e-05,
      "loss": 0.0177,
      "step": 426000
    },
    {
      "epoch": 68.32,
      "grad_norm": 0.45469745993614197,
      "learning_rate": 1.5853200000000003e-05,
      "loss": 0.0183,
      "step": 427000
    },
    {
      "epoch": 68.48,
      "grad_norm": 0.9211979508399963,
      "learning_rate": 1.5773280000000002e-05,
      "loss": 0.0184,
      "step": 428000
    },
    {
      "epoch": 68.64,
      "grad_norm": 0.26601478457450867,
      "learning_rate": 1.5693280000000003e-05,
      "loss": 0.0187,
      "step": 429000
    },
    {
      "epoch": 68.8,
      "grad_norm": 0.33046621084213257,
      "learning_rate": 1.561328e-05,
      "loss": 0.0199,
      "step": 430000
    },
    {
      "epoch": 68.96,
      "grad_norm": 0.08569414168596268,
      "learning_rate": 1.553336e-05,
      "loss": 0.0207,
      "step": 431000
    },
    {
      "epoch": 69.12,
      "grad_norm": 0.054629549384117126,
      "learning_rate": 1.545336e-05,
      "loss": 0.0175,
      "step": 432000
    },
    {
      "epoch": 69.28,
      "grad_norm": 0.3367522358894348,
      "learning_rate": 1.537336e-05,
      "loss": 0.0174,
      "step": 433000
    },
    {
      "epoch": 69.44,
      "grad_norm": 0.7472039461135864,
      "learning_rate": 1.5293360000000002e-05,
      "loss": 0.0172,
      "step": 434000
    },
    {
      "epoch": 69.6,
      "grad_norm": 0.9610616564750671,
      "learning_rate": 1.5213440000000002e-05,
      "loss": 0.0189,
      "step": 435000
    },
    {
      "epoch": 69.76,
      "grad_norm": 0.0851077064871788,
      "learning_rate": 1.5133440000000001e-05,
      "loss": 0.0204,
      "step": 436000
    },
    {
      "epoch": 69.92,
      "grad_norm": 0.8997807502746582,
      "learning_rate": 1.5053600000000001e-05,
      "loss": 0.0206,
      "step": 437000
    },
    {
      "epoch": 70.08,
      "grad_norm": 0.4818531572818756,
      "learning_rate": 1.4973600000000002e-05,
      "loss": 0.0181,
      "step": 438000
    },
    {
      "epoch": 70.24,
      "grad_norm": 0.7860470414161682,
      "learning_rate": 1.4893680000000001e-05,
      "loss": 0.0162,
      "step": 439000
    },
    {
      "epoch": 70.4,
      "grad_norm": 0.19068850576877594,
      "learning_rate": 1.4813680000000002e-05,
      "loss": 0.0168,
      "step": 440000
    },
    {
      "epoch": 70.56,
      "grad_norm": 0.2490914911031723,
      "learning_rate": 1.473368e-05,
      "loss": 0.0171,
      "step": 441000
    },
    {
      "epoch": 70.72,
      "grad_norm": 0.2503839433193207,
      "learning_rate": 1.4653759999999999e-05,
      "loss": 0.0184,
      "step": 442000
    },
    {
      "epoch": 70.88,
      "grad_norm": 0.5976216197013855,
      "learning_rate": 1.457376e-05,
      "loss": 0.0203,
      "step": 443000
    },
    {
      "epoch": 71.04,
      "grad_norm": 0.7411506772041321,
      "learning_rate": 1.449384e-05,
      "loss": 0.0201,
      "step": 444000
    },
    {
      "epoch": 71.2,
      "grad_norm": 0.6006219387054443,
      "learning_rate": 1.441384e-05,
      "loss": 0.0158,
      "step": 445000
    },
    {
      "epoch": 71.36,
      "grad_norm": 0.24981901049613953,
      "learning_rate": 1.4333840000000001e-05,
      "loss": 0.0165,
      "step": 446000
    },
    {
      "epoch": 71.52,
      "grad_norm": 3.1413228511810303,
      "learning_rate": 1.425392e-05,
      "loss": 0.0173,
      "step": 447000
    },
    {
      "epoch": 71.68,
      "grad_norm": 0.06196020543575287,
      "learning_rate": 1.4173920000000001e-05,
      "loss": 0.0174,
      "step": 448000
    },
    {
      "epoch": 71.84,
      "grad_norm": 0.10127104073762894,
      "learning_rate": 1.4093919999999999e-05,
      "loss": 0.0192,
      "step": 449000
    },
    {
      "epoch": 72.0,
      "grad_norm": 1.088147521018982,
      "learning_rate": 1.4014e-05,
      "loss": 0.0201,
      "step": 450000
    },
    {
      "epoch": 72.16,
      "grad_norm": 0.06904806196689606,
      "learning_rate": 1.3933999999999999e-05,
      "loss": 0.0152,
      "step": 451000
    },
    {
      "epoch": 72.32,
      "grad_norm": 0.13941003382205963,
      "learning_rate": 1.3854e-05,
      "loss": 0.0164,
      "step": 452000
    },
    {
      "epoch": 72.48,
      "grad_norm": 0.8923892974853516,
      "learning_rate": 1.3774e-05,
      "loss": 0.0169,
      "step": 453000
    },
    {
      "epoch": 72.64,
      "grad_norm": 0.8758997917175293,
      "learning_rate": 1.369408e-05,
      "loss": 0.0174,
      "step": 454000
    },
    {
      "epoch": 72.8,
      "grad_norm": 0.8640645742416382,
      "learning_rate": 1.3614080000000001e-05,
      "loss": 0.018,
      "step": 455000
    },
    {
      "epoch": 72.96,
      "grad_norm": 0.9522745013237,
      "learning_rate": 1.3534080000000002e-05,
      "loss": 0.0199,
      "step": 456000
    },
    {
      "epoch": 73.12,
      "grad_norm": 1.1684061288833618,
      "learning_rate": 1.3454079999999999e-05,
      "loss": 0.0162,
      "step": 457000
    },
    {
      "epoch": 73.28,
      "grad_norm": 0.8412169814109802,
      "learning_rate": 1.3374159999999999e-05,
      "loss": 0.0162,
      "step": 458000
    },
    {
      "epoch": 73.44,
      "grad_norm": 0.1321033090353012,
      "learning_rate": 1.329416e-05,
      "loss": 0.0161,
      "step": 459000
    },
    {
      "epoch": 73.6,
      "grad_norm": 0.5631558895111084,
      "learning_rate": 1.321424e-05,
      "loss": 0.0165,
      "step": 460000
    },
    {
      "epoch": 73.76,
      "grad_norm": 1.0762791633605957,
      "learning_rate": 1.313432e-05,
      "loss": 0.0183,
      "step": 461000
    },
    {
      "epoch": 73.92,
      "grad_norm": 0.7052088975906372,
      "learning_rate": 1.3054320000000001e-05,
      "loss": 0.0184,
      "step": 462000
    },
    {
      "epoch": 74.08,
      "grad_norm": 0.5714403986930847,
      "learning_rate": 1.297432e-05,
      "loss": 0.0167,
      "step": 463000
    },
    {
      "epoch": 74.24,
      "grad_norm": 0.44551748037338257,
      "learning_rate": 1.2894320000000001e-05,
      "loss": 0.0151,
      "step": 464000
    },
    {
      "epoch": 74.4,
      "grad_norm": 0.9641959071159363,
      "learning_rate": 1.2814400000000002e-05,
      "loss": 0.0149,
      "step": 465000
    },
    {
      "epoch": 74.56,
      "grad_norm": 0.2253846824169159,
      "learning_rate": 1.2734480000000002e-05,
      "loss": 0.016,
      "step": 466000
    },
    {
      "epoch": 74.72,
      "grad_norm": 0.31682103872299194,
      "learning_rate": 1.2654480000000003e-05,
      "loss": 0.0173,
      "step": 467000
    },
    {
      "epoch": 74.88,
      "grad_norm": 0.08352832496166229,
      "learning_rate": 1.257448e-05,
      "loss": 0.0175,
      "step": 468000
    },
    {
      "epoch": 75.04,
      "grad_norm": 0.5264811515808105,
      "learning_rate": 1.2494560000000001e-05,
      "loss": 0.0186,
      "step": 469000
    },
    {
      "epoch": 75.2,
      "grad_norm": 0.41644808650016785,
      "learning_rate": 1.241456e-05,
      "loss": 0.0153,
      "step": 470000
    },
    {
      "epoch": 75.36,
      "grad_norm": 0.07939448207616806,
      "learning_rate": 1.2334560000000001e-05,
      "loss": 0.0154,
      "step": 471000
    },
    {
      "epoch": 75.52,
      "grad_norm": 0.7584318518638611,
      "learning_rate": 1.225464e-05,
      "loss": 0.0159,
      "step": 472000
    },
    {
      "epoch": 75.68,
      "grad_norm": 0.01693858951330185,
      "learning_rate": 1.2174640000000001e-05,
      "loss": 0.0162,
      "step": 473000
    },
    {
      "epoch": 75.84,
      "grad_norm": 0.15525317192077637,
      "learning_rate": 1.209464e-05,
      "loss": 0.0175,
      "step": 474000
    },
    {
      "epoch": 76.0,
      "grad_norm": 1.1823172569274902,
      "learning_rate": 1.2014640000000001e-05,
      "loss": 0.0175,
      "step": 475000
    },
    {
      "epoch": 76.16,
      "grad_norm": 0.27248942852020264,
      "learning_rate": 1.193472e-05,
      "loss": 0.0146,
      "step": 476000
    },
    {
      "epoch": 76.32,
      "grad_norm": 0.833048403263092,
      "learning_rate": 1.1854720000000002e-05,
      "loss": 0.0152,
      "step": 477000
    },
    {
      "epoch": 76.48,
      "grad_norm": 0.5699361562728882,
      "learning_rate": 1.1774800000000001e-05,
      "loss": 0.0157,
      "step": 478000
    },
    {
      "epoch": 76.64,
      "grad_norm": 0.9265400767326355,
      "learning_rate": 1.16948e-05,
      "loss": 0.0163,
      "step": 479000
    },
    {
      "epoch": 76.8,
      "grad_norm": 1.1483721733093262,
      "learning_rate": 1.161488e-05,
      "loss": 0.0162,
      "step": 480000
    },
    {
      "epoch": 76.96,
      "grad_norm": 0.01651478372514248,
      "learning_rate": 1.153488e-05,
      "loss": 0.0184,
      "step": 481000
    },
    {
      "epoch": 77.12,
      "grad_norm": 0.03483320027589798,
      "learning_rate": 1.1454880000000001e-05,
      "loss": 0.0151,
      "step": 482000
    },
    {
      "epoch": 77.28,
      "grad_norm": 0.8829641938209534,
      "learning_rate": 1.137488e-05,
      "loss": 0.0143,
      "step": 483000
    },
    {
      "epoch": 77.44,
      "grad_norm": 0.26654401421546936,
      "learning_rate": 1.129504e-05,
      "loss": 0.0161,
      "step": 484000
    },
    {
      "epoch": 77.6,
      "grad_norm": 0.3660300672054291,
      "learning_rate": 1.121504e-05,
      "loss": 0.0145,
      "step": 485000
    },
    {
      "epoch": 77.76,
      "grad_norm": 0.1993499994277954,
      "learning_rate": 1.113504e-05,
      "loss": 0.0156,
      "step": 486000
    },
    {
      "epoch": 77.92,
      "grad_norm": 0.10728338360786438,
      "learning_rate": 1.105504e-05,
      "loss": 0.0159,
      "step": 487000
    },
    {
      "epoch": 78.08,
      "grad_norm": 0.18937575817108154,
      "learning_rate": 1.0975119999999999e-05,
      "loss": 0.0155,
      "step": 488000
    },
    {
      "epoch": 78.24,
      "grad_norm": 0.7305836081504822,
      "learning_rate": 1.089512e-05,
      "loss": 0.0138,
      "step": 489000
    },
    {
      "epoch": 78.4,
      "grad_norm": 0.7845491170883179,
      "learning_rate": 1.0815200000000001e-05,
      "loss": 0.0142,
      "step": 490000
    },
    {
      "epoch": 78.56,
      "grad_norm": 0.23798829317092896,
      "learning_rate": 1.07352e-05,
      "loss": 0.015,
      "step": 491000
    },
    {
      "epoch": 78.72,
      "grad_norm": 0.8625748157501221,
      "learning_rate": 1.06552e-05,
      "loss": 0.0154,
      "step": 492000
    },
    {
      "epoch": 78.88,
      "grad_norm": 0.05311914160847664,
      "learning_rate": 1.05752e-05,
      "loss": 0.0157,
      "step": 493000
    },
    {
      "epoch": 79.04,
      "grad_norm": 0.6807913780212402,
      "learning_rate": 1.049528e-05,
      "loss": 0.0167,
      "step": 494000
    },
    {
      "epoch": 79.2,
      "grad_norm": 0.5190921425819397,
      "learning_rate": 1.041528e-05,
      "loss": 0.0131,
      "step": 495000
    },
    {
      "epoch": 79.36,
      "grad_norm": 0.14602991938591003,
      "learning_rate": 1.0335360000000002e-05,
      "loss": 0.0142,
      "step": 496000
    },
    {
      "epoch": 79.52,
      "grad_norm": 0.7048643231391907,
      "learning_rate": 1.025536e-05,
      "loss": 0.0144,
      "step": 497000
    },
    {
      "epoch": 79.68,
      "grad_norm": 1.4666693210601807,
      "learning_rate": 1.017536e-05,
      "loss": 0.0149,
      "step": 498000
    },
    {
      "epoch": 79.84,
      "grad_norm": 0.8463094830513,
      "learning_rate": 1.009536e-05,
      "loss": 0.0163,
      "step": 499000
    },
    {
      "epoch": 80.0,
      "grad_norm": 0.18470057845115662,
      "learning_rate": 1.001552e-05,
      "loss": 0.0168,
      "step": 500000
    },
    {
      "epoch": 80.16,
      "grad_norm": 0.1932750642299652,
      "learning_rate": 9.935520000000001e-06,
      "loss": 0.014,
      "step": 501000
    },
    {
      "epoch": 80.32,
      "grad_norm": 2.6808886528015137,
      "learning_rate": 9.85552e-06,
      "loss": 0.0143,
      "step": 502000
    },
    {
      "epoch": 80.48,
      "grad_norm": 0.2778271436691284,
      "learning_rate": 9.775520000000001e-06,
      "loss": 0.014,
      "step": 503000
    },
    {
      "epoch": 80.64,
      "grad_norm": 1.0169310569763184,
      "learning_rate": 9.6956e-06,
      "loss": 0.0144,
      "step": 504000
    },
    {
      "epoch": 80.8,
      "grad_norm": 1.0368585586547852,
      "learning_rate": 9.615600000000002e-06,
      "loss": 0.0147,
      "step": 505000
    },
    {
      "epoch": 80.96,
      "grad_norm": 0.7057197690010071,
      "learning_rate": 9.535680000000001e-06,
      "loss": 0.0164,
      "step": 506000
    },
    {
      "epoch": 81.12,
      "grad_norm": 0.05516259744763374,
      "learning_rate": 9.45568e-06,
      "loss": 0.0144,
      "step": 507000
    },
    {
      "epoch": 81.28,
      "grad_norm": 0.497761994600296,
      "learning_rate": 9.375680000000001e-06,
      "loss": 0.0138,
      "step": 508000
    },
    {
      "epoch": 81.44,
      "grad_norm": 0.4006448984146118,
      "learning_rate": 9.295680000000002e-06,
      "loss": 0.0135,
      "step": 509000
    },
    {
      "epoch": 81.6,
      "grad_norm": 0.7380945086479187,
      "learning_rate": 9.215760000000001e-06,
      "loss": 0.0143,
      "step": 510000
    },
    {
      "epoch": 81.76,
      "grad_norm": 0.11041159182786942,
      "learning_rate": 9.13576e-06,
      "loss": 0.0149,
      "step": 511000
    },
    {
      "epoch": 81.92,
      "grad_norm": 0.04816296324133873,
      "learning_rate": 9.05584e-06,
      "loss": 0.0154,
      "step": 512000
    },
    {
      "epoch": 82.08,
      "grad_norm": 0.8121826648712158,
      "learning_rate": 8.97584e-06,
      "loss": 0.0143,
      "step": 513000
    },
    {
      "epoch": 82.24,
      "grad_norm": 0.718228816986084,
      "learning_rate": 8.895840000000002e-06,
      "loss": 0.0135,
      "step": 514000
    },
    {
      "epoch": 82.4,
      "grad_norm": 0.04824339598417282,
      "learning_rate": 8.81592e-06,
      "loss": 0.0136,
      "step": 515000
    },
    {
      "epoch": 82.56,
      "grad_norm": 0.18122504651546478,
      "learning_rate": 8.73592e-06,
      "loss": 0.0138,
      "step": 516000
    },
    {
      "epoch": 82.72,
      "grad_norm": 0.17570751905441284,
      "learning_rate": 8.655920000000001e-06,
      "loss": 0.0145,
      "step": 517000
    },
    {
      "epoch": 82.88,
      "grad_norm": 0.3693999648094177,
      "learning_rate": 8.576e-06,
      "loss": 0.0158,
      "step": 518000
    },
    {
      "epoch": 83.04,
      "grad_norm": 0.10620351880788803,
      "learning_rate": 8.496e-06,
      "loss": 0.0142,
      "step": 519000
    },
    {
      "epoch": 83.2,
      "grad_norm": 0.20061875879764557,
      "learning_rate": 8.416e-06,
      "loss": 0.0121,
      "step": 520000
    },
    {
      "epoch": 83.36,
      "grad_norm": 1.0188194513320923,
      "learning_rate": 8.33608e-06,
      "loss": 0.0134,
      "step": 521000
    },
    {
      "epoch": 83.52,
      "grad_norm": 0.5154218077659607,
      "learning_rate": 8.25608e-06,
      "loss": 0.0137,
      "step": 522000
    },
    {
      "epoch": 83.68,
      "grad_norm": 0.0367082804441452,
      "learning_rate": 8.17616e-06,
      "loss": 0.0139,
      "step": 523000
    },
    {
      "epoch": 83.84,
      "grad_norm": 1.1121872663497925,
      "learning_rate": 8.09616e-06,
      "loss": 0.0145,
      "step": 524000
    },
    {
      "epoch": 84.0,
      "grad_norm": 1.0181961059570312,
      "learning_rate": 8.01616e-06,
      "loss": 0.0151,
      "step": 525000
    },
    {
      "epoch": 84.16,
      "grad_norm": 0.07555820792913437,
      "learning_rate": 7.936160000000001e-06,
      "loss": 0.0123,
      "step": 526000
    },
    {
      "epoch": 84.32,
      "grad_norm": 0.25937962532043457,
      "learning_rate": 7.85624e-06,
      "loss": 0.0132,
      "step": 527000
    },
    {
      "epoch": 84.48,
      "grad_norm": 0.31190288066864014,
      "learning_rate": 7.77624e-06,
      "loss": 0.013,
      "step": 528000
    },
    {
      "epoch": 84.64,
      "grad_norm": 0.5118504166603088,
      "learning_rate": 7.69632e-06,
      "loss": 0.0134,
      "step": 529000
    },
    {
      "epoch": 84.8,
      "grad_norm": 0.6615209579467773,
      "learning_rate": 7.6164e-06,
      "loss": 0.0144,
      "step": 530000
    },
    {
      "epoch": 84.96,
      "grad_norm": 0.1655469834804535,
      "learning_rate": 7.5364e-06,
      "loss": 0.0147,
      "step": 531000
    },
    {
      "epoch": 85.12,
      "grad_norm": 0.3633967339992523,
      "learning_rate": 7.456400000000001e-06,
      "loss": 0.013,
      "step": 532000
    },
    {
      "epoch": 85.28,
      "grad_norm": 0.17260777950286865,
      "learning_rate": 7.376480000000001e-06,
      "loss": 0.013,
      "step": 533000
    },
    {
      "epoch": 85.44,
      "grad_norm": 0.7751312851905823,
      "learning_rate": 7.29648e-06,
      "loss": 0.0136,
      "step": 534000
    },
    {
      "epoch": 85.6,
      "grad_norm": 0.4645666778087616,
      "learning_rate": 7.2164800000000006e-06,
      "loss": 0.0132,
      "step": 535000
    },
    {
      "epoch": 85.76,
      "grad_norm": 0.8303845524787903,
      "learning_rate": 7.136480000000001e-06,
      "loss": 0.0134,
      "step": 536000
    },
    {
      "epoch": 85.92,
      "grad_norm": 0.7960656881332397,
      "learning_rate": 7.056640000000001e-06,
      "loss": 0.0137,
      "step": 537000
    },
    {
      "epoch": 86.08,
      "grad_norm": 0.36585724353790283,
      "learning_rate": 6.976640000000001e-06,
      "loss": 0.014,
      "step": 538000
    },
    {
      "epoch": 86.24,
      "grad_norm": 0.1475101113319397,
      "learning_rate": 6.8966400000000004e-06,
      "loss": 0.0124,
      "step": 539000
    },
    {
      "epoch": 86.4,
      "grad_norm": 0.10542421042919159,
      "learning_rate": 6.81664e-06,
      "loss": 0.0121,
      "step": 540000
    },
    {
      "epoch": 86.56,
      "grad_norm": 1.987738847732544,
      "learning_rate": 6.736720000000001e-06,
      "loss": 0.0135,
      "step": 541000
    },
    {
      "epoch": 86.72,
      "grad_norm": 0.11341362446546555,
      "learning_rate": 6.6568e-06,
      "loss": 0.0139,
      "step": 542000
    },
    {
      "epoch": 86.88,
      "grad_norm": 0.05860774964094162,
      "learning_rate": 6.5767999999999994e-06,
      "loss": 0.0145,
      "step": 543000
    },
    {
      "epoch": 87.04,
      "grad_norm": 0.041633374989032745,
      "learning_rate": 6.49688e-06,
      "loss": 0.0136,
      "step": 544000
    },
    {
      "epoch": 87.2,
      "grad_norm": 1.8256194591522217,
      "learning_rate": 6.41688e-06,
      "loss": 0.0119,
      "step": 545000
    },
    {
      "epoch": 87.36,
      "grad_norm": 0.9907539486885071,
      "learning_rate": 6.3368800000000006e-06,
      "loss": 0.0122,
      "step": 546000
    },
    {
      "epoch": 87.52,
      "grad_norm": 0.1706804484128952,
      "learning_rate": 6.256960000000001e-06,
      "loss": 0.0131,
      "step": 547000
    },
    {
      "epoch": 87.68,
      "grad_norm": 1.701629877090454,
      "learning_rate": 6.17696e-06,
      "loss": 0.013,
      "step": 548000
    },
    {
      "epoch": 87.84,
      "grad_norm": 0.04239574074745178,
      "learning_rate": 6.0970400000000005e-06,
      "loss": 0.0132,
      "step": 549000
    },
    {
      "epoch": 88.0,
      "grad_norm": 0.04959522932767868,
      "learning_rate": 6.01704e-06,
      "loss": 0.0144,
      "step": 550000
    },
    {
      "epoch": 88.16,
      "grad_norm": 0.16353994607925415,
      "learning_rate": 5.93712e-06,
      "loss": 0.0131,
      "step": 551000
    },
    {
      "epoch": 88.32,
      "grad_norm": 0.3805541694164276,
      "learning_rate": 5.85712e-06,
      "loss": 0.0122,
      "step": 552000
    },
    {
      "epoch": 88.48,
      "grad_norm": 1.2248464822769165,
      "learning_rate": 5.777120000000001e-06,
      "loss": 0.013,
      "step": 553000
    },
    {
      "epoch": 88.64,
      "grad_norm": 1.3038363456726074,
      "learning_rate": 5.6972e-06,
      "loss": 0.0138,
      "step": 554000
    },
    {
      "epoch": 88.8,
      "grad_norm": 0.043366722762584686,
      "learning_rate": 5.6172e-06,
      "loss": 0.0131,
      "step": 555000
    },
    {
      "epoch": 88.96,
      "grad_norm": 0.44728198647499084,
      "learning_rate": 5.5372e-06,
      "loss": 0.0135,
      "step": 556000
    },
    {
      "epoch": 89.12,
      "grad_norm": 0.4996417760848999,
      "learning_rate": 5.45728e-06,
      "loss": 0.0123,
      "step": 557000
    },
    {
      "epoch": 89.28,
      "grad_norm": 0.5743764638900757,
      "learning_rate": 5.3772800000000005e-06,
      "loss": 0.012,
      "step": 558000
    },
    {
      "epoch": 89.44,
      "grad_norm": 0.9362891912460327,
      "learning_rate": 5.29728e-06,
      "loss": 0.0122,
      "step": 559000
    },
    {
      "epoch": 89.6,
      "grad_norm": 1.1948965787887573,
      "learning_rate": 5.21728e-06,
      "loss": 0.013,
      "step": 560000
    },
    {
      "epoch": 89.76,
      "grad_norm": 0.07814314216375351,
      "learning_rate": 5.13736e-06,
      "loss": 0.0131,
      "step": 561000
    },
    {
      "epoch": 89.92,
      "grad_norm": 0.6145501732826233,
      "learning_rate": 5.057360000000001e-06,
      "loss": 0.0133,
      "step": 562000
    },
    {
      "epoch": 90.08,
      "grad_norm": 0.7517486810684204,
      "learning_rate": 4.97744e-06,
      "loss": 0.012,
      "step": 563000
    },
    {
      "epoch": 90.24,
      "grad_norm": 0.057227227836847305,
      "learning_rate": 4.89744e-06,
      "loss": 0.0124,
      "step": 564000
    },
    {
      "epoch": 90.4,
      "grad_norm": 0.5493927597999573,
      "learning_rate": 4.81744e-06,
      "loss": 0.0125,
      "step": 565000
    },
    {
      "epoch": 90.56,
      "grad_norm": 0.17681044340133667,
      "learning_rate": 4.73744e-06,
      "loss": 0.0121,
      "step": 566000
    },
    {
      "epoch": 90.72,
      "grad_norm": 0.41989174485206604,
      "learning_rate": 4.6576e-06,
      "loss": 0.0123,
      "step": 567000
    },
    {
      "epoch": 90.88,
      "grad_norm": 0.15114516019821167,
      "learning_rate": 4.5776e-06,
      "loss": 0.0133,
      "step": 568000
    },
    {
      "epoch": 91.04,
      "grad_norm": 0.17983782291412354,
      "learning_rate": 4.49768e-06,
      "loss": 0.0136,
      "step": 569000
    },
    {
      "epoch": 91.2,
      "grad_norm": 0.32102087140083313,
      "learning_rate": 4.41768e-06,
      "loss": 0.0122,
      "step": 570000
    },
    {
      "epoch": 91.36,
      "grad_norm": 1.1988993883132935,
      "learning_rate": 4.33768e-06,
      "loss": 0.0128,
      "step": 571000
    },
    {
      "epoch": 91.52,
      "grad_norm": 0.17791874706745148,
      "learning_rate": 4.25768e-06,
      "loss": 0.0123,
      "step": 572000
    },
    {
      "epoch": 91.68,
      "grad_norm": 0.2415514588356018,
      "learning_rate": 4.17776e-06,
      "loss": 0.0121,
      "step": 573000
    },
    {
      "epoch": 91.84,
      "grad_norm": 0.8471096158027649,
      "learning_rate": 4.09784e-06,
      "loss": 0.0125,
      "step": 574000
    },
    {
      "epoch": 92.0,
      "grad_norm": 0.06502803415060043,
      "learning_rate": 4.01784e-06,
      "loss": 0.0126,
      "step": 575000
    },
    {
      "epoch": 92.16,
      "grad_norm": 0.6225605607032776,
      "learning_rate": 3.93784e-06,
      "loss": 0.0123,
      "step": 576000
    },
    {
      "epoch": 92.32,
      "grad_norm": 0.5083337426185608,
      "learning_rate": 3.85784e-06,
      "loss": 0.0115,
      "step": 577000
    },
    {
      "epoch": 92.48,
      "grad_norm": 1.101757526397705,
      "learning_rate": 3.778e-06,
      "loss": 0.0126,
      "step": 578000
    },
    {
      "epoch": 92.64,
      "grad_norm": 0.09496854990720749,
      "learning_rate": 3.698e-06,
      "loss": 0.012,
      "step": 579000
    },
    {
      "epoch": 92.8,
      "grad_norm": 0.38054296374320984,
      "learning_rate": 3.618e-06,
      "loss": 0.0121,
      "step": 580000
    },
    {
      "epoch": 92.96,
      "grad_norm": 1.3479819297790527,
      "learning_rate": 3.5380000000000003e-06,
      "loss": 0.0129,
      "step": 581000
    },
    {
      "epoch": 93.12,
      "grad_norm": 0.38941121101379395,
      "learning_rate": 3.4580800000000003e-06,
      "loss": 0.012,
      "step": 582000
    },
    {
      "epoch": 93.28,
      "grad_norm": 0.4173058867454529,
      "learning_rate": 3.3781600000000003e-06,
      "loss": 0.0124,
      "step": 583000
    },
    {
      "epoch": 93.44,
      "grad_norm": 0.19527184963226318,
      "learning_rate": 3.29816e-06,
      "loss": 0.012,
      "step": 584000
    },
    {
      "epoch": 93.6,
      "grad_norm": 0.9169588685035706,
      "learning_rate": 3.21816e-06,
      "loss": 0.0123,
      "step": 585000
    },
    {
      "epoch": 93.76,
      "grad_norm": 0.17707982659339905,
      "learning_rate": 3.13824e-06,
      "loss": 0.0125,
      "step": 586000
    },
    {
      "epoch": 93.92,
      "grad_norm": 0.5470887422561646,
      "learning_rate": 3.05824e-06,
      "loss": 0.0125,
      "step": 587000
    },
    {
      "epoch": 94.08,
      "grad_norm": 0.005555886775255203,
      "learning_rate": 2.9782400000000004e-06,
      "loss": 0.0121,
      "step": 588000
    },
    {
      "epoch": 94.24,
      "grad_norm": 0.3644116222858429,
      "learning_rate": 2.89824e-06,
      "loss": 0.0116,
      "step": 589000
    },
    {
      "epoch": 94.4,
      "grad_norm": 0.05877487733960152,
      "learning_rate": 2.81832e-06,
      "loss": 0.0124,
      "step": 590000
    },
    {
      "epoch": 94.56,
      "grad_norm": 0.5024577379226685,
      "learning_rate": 2.7383200000000002e-06,
      "loss": 0.0121,
      "step": 591000
    },
    {
      "epoch": 94.72,
      "grad_norm": 0.7019615173339844,
      "learning_rate": 2.65832e-06,
      "loss": 0.0123,
      "step": 592000
    },
    {
      "epoch": 94.88,
      "grad_norm": 0.049814820289611816,
      "learning_rate": 2.57832e-06,
      "loss": 0.0119,
      "step": 593000
    },
    {
      "epoch": 95.04,
      "grad_norm": 0.35971447825431824,
      "learning_rate": 2.4984e-06,
      "loss": 0.0123,
      "step": 594000
    },
    {
      "epoch": 95.2,
      "grad_norm": 1.4777123928070068,
      "learning_rate": 2.41848e-06,
      "loss": 0.0121,
      "step": 595000
    },
    {
      "epoch": 95.36,
      "grad_norm": 0.4199833273887634,
      "learning_rate": 2.33848e-06,
      "loss": 0.0115,
      "step": 596000
    },
    {
      "epoch": 95.52,
      "grad_norm": 0.12826167047023773,
      "learning_rate": 2.25848e-06,
      "loss": 0.0119,
      "step": 597000
    },
    {
      "epoch": 95.68,
      "grad_norm": 0.1779615879058838,
      "learning_rate": 2.17856e-06,
      "loss": 0.0132,
      "step": 598000
    },
    {
      "epoch": 95.84,
      "grad_norm": 0.13940471410751343,
      "learning_rate": 2.0985600000000003e-06,
      "loss": 0.0124,
      "step": 599000
    },
    {
      "epoch": 96.0,
      "grad_norm": 0.0959380716085434,
      "learning_rate": 2.01856e-06,
      "loss": 0.0117,
      "step": 600000
    },
    {
      "epoch": 96.16,
      "grad_norm": 0.8122072219848633,
      "learning_rate": 1.93856e-06,
      "loss": 0.0113,
      "step": 601000
    },
    {
      "epoch": 96.32,
      "grad_norm": 0.09752124547958374,
      "learning_rate": 1.8585600000000003e-06,
      "loss": 0.0118,
      "step": 602000
    },
    {
      "epoch": 96.48,
      "grad_norm": 1.5333572626113892,
      "learning_rate": 1.7787200000000001e-06,
      "loss": 0.0122,
      "step": 603000
    },
    {
      "epoch": 96.64,
      "grad_norm": 0.5379500985145569,
      "learning_rate": 1.6987200000000003e-06,
      "loss": 0.013,
      "step": 604000
    },
    {
      "epoch": 96.8,
      "grad_norm": 0.49674442410469055,
      "learning_rate": 1.61872e-06,
      "loss": 0.0114,
      "step": 605000
    },
    {
      "epoch": 96.96,
      "grad_norm": 0.7012593150138855,
      "learning_rate": 1.5388000000000002e-06,
      "loss": 0.0118,
      "step": 606000
    },
    {
      "epoch": 97.12,
      "grad_norm": 0.7070223689079285,
      "learning_rate": 1.4588000000000001e-06,
      "loss": 0.0125,
      "step": 607000
    },
    {
      "epoch": 97.28,
      "grad_norm": 0.12657305598258972,
      "learning_rate": 1.3788e-06,
      "loss": 0.0114,
      "step": 608000
    },
    {
      "epoch": 97.44,
      "grad_norm": 0.48508235812187195,
      "learning_rate": 1.2988e-06,
      "loss": 0.0115,
      "step": 609000
    },
    {
      "epoch": 97.6,
      "grad_norm": 0.18493975698947906,
      "learning_rate": 1.21888e-06,
      "loss": 0.0115,
      "step": 610000
    },
    {
      "epoch": 97.76,
      "grad_norm": 2.0739643573760986,
      "learning_rate": 1.1388799999999999e-06,
      "loss": 0.0116,
      "step": 611000
    },
    {
      "epoch": 97.92,
      "grad_norm": 0.8314780592918396,
      "learning_rate": 1.05904e-06,
      "loss": 0.0121,
      "step": 612000
    },
    {
      "epoch": 98.08,
      "grad_norm": 0.25113770365715027,
      "learning_rate": 9.7904e-07,
      "loss": 0.0121,
      "step": 613000
    },
    {
      "epoch": 98.24,
      "grad_norm": 0.7490771412849426,
      "learning_rate": 8.990400000000001e-07,
      "loss": 0.0119,
      "step": 614000
    },
    {
      "epoch": 98.4,
      "grad_norm": 0.5917113423347473,
      "learning_rate": 8.191199999999999e-07,
      "loss": 0.0117,
      "step": 615000
    },
    {
      "epoch": 98.56,
      "grad_norm": 1.0027462244033813,
      "learning_rate": 7.3912e-07,
      "loss": 0.0116,
      "step": 616000
    },
    {
      "epoch": 98.72,
      "grad_norm": 0.18923528492450714,
      "learning_rate": 6.591200000000001e-07,
      "loss": 0.0111,
      "step": 617000
    },
    {
      "epoch": 98.88,
      "grad_norm": 0.2844529151916504,
      "learning_rate": 5.7912e-07,
      "loss": 0.0113,
      "step": 618000
    },
    {
      "epoch": 99.04,
      "grad_norm": 0.011866113170981407,
      "learning_rate": 4.9912e-07,
      "loss": 0.0116,
      "step": 619000
    },
    {
      "epoch": 99.2,
      "grad_norm": 0.8934244513511658,
      "learning_rate": 4.1928000000000003e-07,
      "loss": 0.0121,
      "step": 620000
    },
    {
      "epoch": 99.36,
      "grad_norm": 0.06510012596845627,
      "learning_rate": 3.3928e-07,
      "loss": 0.0118,
      "step": 621000
    },
    {
      "epoch": 99.52,
      "grad_norm": 1.0785808563232422,
      "learning_rate": 2.5928000000000003e-07,
      "loss": 0.0115,
      "step": 622000
    },
    {
      "epoch": 99.68,
      "grad_norm": 0.33693695068359375,
      "learning_rate": 1.7936e-07,
      "loss": 0.0113,
      "step": 623000
    }
  ],
  "logging_steps": 1000,
  "max_steps": 625000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 653369505600000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
