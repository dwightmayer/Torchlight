{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 99.84,
  "eval_steps": 500,
  "global_step": 624000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.6,
      "grad_norm": 5.1469645500183105,
      "learning_rate": 4.920032e-05,
      "loss": 0.4018,
      "step": 10000
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.6975059509277344,
      "learning_rate": 4.840064e-05,
      "loss": 0.2697,
      "step": 20000
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.480501651763916,
      "learning_rate": 4.760096e-05,
      "loss": 0.207,
      "step": 30000
    },
    {
      "epoch": 6.4,
      "grad_norm": 3.1323790550231934,
      "learning_rate": 4.680128e-05,
      "loss": 0.1698,
      "step": 40000
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.5021090507507324,
      "learning_rate": 4.600168e-05,
      "loss": 0.1464,
      "step": 50000
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.1032319068908691,
      "learning_rate": 4.5202e-05,
      "loss": 0.1218,
      "step": 60000
    },
    {
      "epoch": 11.2,
      "grad_norm": 2.6606531143188477,
      "learning_rate": 4.44024e-05,
      "loss": 0.1121,
      "step": 70000
    },
    {
      "epoch": 12.8,
      "grad_norm": 1.6309789419174194,
      "learning_rate": 4.360272e-05,
      "loss": 0.0981,
      "step": 80000
    },
    {
      "epoch": 14.4,
      "grad_norm": 1.6442627906799316,
      "learning_rate": 4.2803120000000005e-05,
      "loss": 0.0898,
      "step": 90000
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.0806262493133545,
      "learning_rate": 4.200352e-05,
      "loss": 0.0844,
      "step": 100000
    },
    {
      "epoch": 17.6,
      "grad_norm": 0.6029794812202454,
      "learning_rate": 4.120392e-05,
      "loss": 0.074,
      "step": 110000
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.14614230394363403,
      "learning_rate": 4.0404320000000003e-05,
      "loss": 0.0724,
      "step": 120000
    },
    {
      "epoch": 20.8,
      "grad_norm": 1.4593576192855835,
      "learning_rate": 3.9604640000000006e-05,
      "loss": 0.0666,
      "step": 130000
    },
    {
      "epoch": 22.4,
      "grad_norm": 1.8618167638778687,
      "learning_rate": 3.880504e-05,
      "loss": 0.0624,
      "step": 140000
    },
    {
      "epoch": 24.0,
      "grad_norm": 1.0959988832473755,
      "learning_rate": 3.800544e-05,
      "loss": 0.061,
      "step": 150000
    },
    {
      "epoch": 25.6,
      "grad_norm": 0.5173755288124084,
      "learning_rate": 3.7205840000000005e-05,
      "loss": 0.0549,
      "step": 160000
    },
    {
      "epoch": 27.2,
      "grad_norm": 1.9876006841659546,
      "learning_rate": 3.640624e-05,
      "loss": 0.0545,
      "step": 170000
    },
    {
      "epoch": 28.8,
      "grad_norm": 2.204888105392456,
      "learning_rate": 3.560664e-05,
      "loss": 0.0519,
      "step": 180000
    },
    {
      "epoch": 30.4,
      "grad_norm": 1.7824963331222534,
      "learning_rate": 3.4807040000000003e-05,
      "loss": 0.0495,
      "step": 190000
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.28336095809936523,
      "learning_rate": 3.400744e-05,
      "loss": 0.0492,
      "step": 200000
    },
    {
      "epoch": 33.6,
      "grad_norm": 1.1875742673873901,
      "learning_rate": 3.320784e-05,
      "loss": 0.0449,
      "step": 210000
    },
    {
      "epoch": 35.2,
      "grad_norm": 1.2804304361343384,
      "learning_rate": 3.240824e-05,
      "loss": 0.0458,
      "step": 220000
    },
    {
      "epoch": 36.8,
      "grad_norm": 0.5434412956237793,
      "learning_rate": 3.1608640000000004e-05,
      "loss": 0.0439,
      "step": 230000
    },
    {
      "epoch": 38.4,
      "grad_norm": 1.277948260307312,
      "learning_rate": 3.080904e-05,
      "loss": 0.0425,
      "step": 240000
    },
    {
      "epoch": 40.0,
      "grad_norm": 1.3525835275650024,
      "learning_rate": 3.000944e-05,
      "loss": 0.0434,
      "step": 250000
    },
    {
      "epoch": 41.6,
      "grad_norm": 1.8090267181396484,
      "learning_rate": 2.920984e-05,
      "loss": 0.0392,
      "step": 260000
    },
    {
      "epoch": 43.2,
      "grad_norm": 1.23197603225708,
      "learning_rate": 2.841008e-05,
      "loss": 0.0408,
      "step": 270000
    },
    {
      "epoch": 44.8,
      "grad_norm": 1.340025544166565,
      "learning_rate": 2.761048e-05,
      "loss": 0.0385,
      "step": 280000
    },
    {
      "epoch": 46.4,
      "grad_norm": 0.9504654407501221,
      "learning_rate": 2.6810800000000004e-05,
      "loss": 0.0374,
      "step": 290000
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.28499749302864075,
      "learning_rate": 2.601112e-05,
      "loss": 0.0379,
      "step": 300000
    },
    {
      "epoch": 49.6,
      "grad_norm": 0.3231699764728546,
      "learning_rate": 2.521152e-05,
      "loss": 0.0352,
      "step": 310000
    },
    {
      "epoch": 51.2,
      "grad_norm": 0.039200179278850555,
      "learning_rate": 2.4411840000000002e-05,
      "loss": 0.0357,
      "step": 320000
    },
    {
      "epoch": 52.8,
      "grad_norm": 0.4448540508747101,
      "learning_rate": 2.3612240000000003e-05,
      "loss": 0.0344,
      "step": 330000
    },
    {
      "epoch": 54.4,
      "grad_norm": 0.9322484731674194,
      "learning_rate": 2.2812640000000002e-05,
      "loss": 0.0336,
      "step": 340000
    },
    {
      "epoch": 56.0,
      "grad_norm": 1.9445159435272217,
      "learning_rate": 2.20128e-05,
      "loss": 0.0342,
      "step": 350000
    },
    {
      "epoch": 57.6,
      "grad_norm": 0.052141301333904266,
      "learning_rate": 2.12132e-05,
      "loss": 0.0315,
      "step": 360000
    },
    {
      "epoch": 59.2,
      "grad_norm": 1.8883227109909058,
      "learning_rate": 2.041352e-05,
      "loss": 0.032,
      "step": 370000
    },
    {
      "epoch": 60.8,
      "grad_norm": 2.0849530696868896,
      "learning_rate": 1.9613920000000003e-05,
      "loss": 0.0312,
      "step": 380000
    },
    {
      "epoch": 62.4,
      "grad_norm": 0.12152915447950363,
      "learning_rate": 1.8814320000000002e-05,
      "loss": 0.0304,
      "step": 390000
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.9877228736877441,
      "learning_rate": 1.801464e-05,
      "loss": 0.0305,
      "step": 400000
    },
    {
      "epoch": 65.6,
      "grad_norm": 1.9897855520248413,
      "learning_rate": 1.7215120000000002e-05,
      "loss": 0.0284,
      "step": 410000
    },
    {
      "epoch": 67.2,
      "grad_norm": 0.8308950066566467,
      "learning_rate": 1.6415360000000003e-05,
      "loss": 0.0286,
      "step": 420000
    },
    {
      "epoch": 68.8,
      "grad_norm": 0.44962912797927856,
      "learning_rate": 1.5615680000000002e-05,
      "loss": 0.0282,
      "step": 430000
    },
    {
      "epoch": 70.4,
      "grad_norm": 0.8690162301063538,
      "learning_rate": 1.4816080000000002e-05,
      "loss": 0.0276,
      "step": 440000
    },
    {
      "epoch": 72.0,
      "grad_norm": 2.1718900203704834,
      "learning_rate": 1.401648e-05,
      "loss": 0.0277,
      "step": 450000
    },
    {
      "epoch": 73.6,
      "grad_norm": 1.31472647190094,
      "learning_rate": 1.3216800000000002e-05,
      "loss": 0.0259,
      "step": 460000
    },
    {
      "epoch": 75.2,
      "grad_norm": 0.2931196093559265,
      "learning_rate": 1.241712e-05,
      "loss": 0.0261,
      "step": 470000
    },
    {
      "epoch": 76.8,
      "grad_norm": 1.5991829633712769,
      "learning_rate": 1.1617440000000001e-05,
      "loss": 0.0256,
      "step": 480000
    },
    {
      "epoch": 78.4,
      "grad_norm": 1.3156293630599976,
      "learning_rate": 1.0817920000000002e-05,
      "loss": 0.0248,
      "step": 490000
    },
    {
      "epoch": 80.0,
      "grad_norm": 1.5237021446228027,
      "learning_rate": 1.001832e-05,
      "loss": 0.0249,
      "step": 500000
    },
    {
      "epoch": 81.6,
      "grad_norm": 0.024301165714859962,
      "learning_rate": 9.21856e-06,
      "loss": 0.0238,
      "step": 510000
    },
    {
      "epoch": 83.2,
      "grad_norm": 0.6027190089225769,
      "learning_rate": 8.41888e-06,
      "loss": 0.0242,
      "step": 520000
    },
    {
      "epoch": 84.8,
      "grad_norm": 1.3531897068023682,
      "learning_rate": 7.6192e-06,
      "loss": 0.0237,
      "step": 530000
    },
    {
      "epoch": 86.4,
      "grad_norm": 0.06656546145677567,
      "learning_rate": 6.819600000000001e-06,
      "loss": 0.0232,
      "step": 540000
    },
    {
      "epoch": 88.0,
      "grad_norm": 1.1939412355422974,
      "learning_rate": 6.01992e-06,
      "loss": 0.0229,
      "step": 550000
    },
    {
      "epoch": 89.6,
      "grad_norm": 0.21795541048049927,
      "learning_rate": 5.220240000000001e-06,
      "loss": 0.0219,
      "step": 560000
    },
    {
      "epoch": 91.2,
      "grad_norm": 0.6955822706222534,
      "learning_rate": 4.42064e-06,
      "loss": 0.0225,
      "step": 570000
    },
    {
      "epoch": 92.8,
      "grad_norm": 0.9418777823448181,
      "learning_rate": 3.6209600000000003e-06,
      "loss": 0.0218,
      "step": 580000
    },
    {
      "epoch": 94.4,
      "grad_norm": 0.07471896708011627,
      "learning_rate": 2.82136e-06,
      "loss": 0.0212,
      "step": 590000
    },
    {
      "epoch": 96.0,
      "grad_norm": 0.2789213955402374,
      "learning_rate": 2.0216000000000003e-06,
      "loss": 0.0212,
      "step": 600000
    },
    {
      "epoch": 97.6,
      "grad_norm": 1.1925779581069946,
      "learning_rate": 1.2220000000000001e-06,
      "loss": 0.0208,
      "step": 610000
    },
    {
      "epoch": 99.2,
      "grad_norm": 0.4498307704925537,
      "learning_rate": 4.2224000000000005e-07,
      "loss": 0.0207,
      "step": 620000
    }
  ],
  "logging_steps": 10000,
  "max_steps": 625000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 654418252800000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
